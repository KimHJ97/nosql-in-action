# 콘솔 도구를 이용한 카프카 클러스터 운영

## 1. 기본 제공되는 콘솔 도구들

 - __프로세스 관련__
    - kafka-server-start|stop.sh
    - zookeeper-server-start|stop.sh
 - __토픽/파티션 관련__
    - kafka-delete-records.sh
    - kafka-get-offsets.sh
    - kafka-leader-election.sh
    - kafka-reassign-partitions.sh
    - kafka-replica-verification.sh
    - kafka-topics.sh
 - __인증/인가/설정 관련__
    - kafka-acls.sh
    - kafka-configs.sh
    - kafka-delegation-tokens.sh
 - __메시지 테스트__
    - kafka-console-consumer|producer.sh
    - kafka-verifiable-consumer|producer.sh
    - kafka-consumer|producer-pref-test.sh

```bash
ls /opt/bitnami/kafka/bin
connect-distributed.sh        kafka-mirror-maker.sh
connect-mirror-maker.sh       kafka-producer-perf-test.sh
connect-standalone.sh         kafka-reassign-partitions.sh
kafka-acls.sh                 kafka-replica-verification.sh
kafka-broker-api-versions.sh  kafka-run-class.sh
kafka-cluster.sh              kafka-server-start.sh
kafka-configs.sh              kafka-server-stop.sh
kafka-console-consumer.sh     kafka-storage.sh
kafka-console-producer.sh     kafka-streams-application-reset.sh
kafka-consumer-groups.sh      kafka-topics.sh
kafka-consumer-perf-test.sh   kafka-transactions.sh
kafka-delegation-tokens.sh    kafka-verifiable-consumer.sh
kafka-delete-records.sh       kafka-verifiable-producer.sh
kafka-dump-log.sh             trogdor.sh
kafka-features.sh             windows
kafka-get-offsets.sh          zookeeper-security-migration.sh
kafka-leader-election.sh      zookeeper-server-start.sh
kafka-log-dirs.sh             zookeeper-server-stop.sh
kafka-metadata-quorum.sh      zookeeper-shell.sh
kafka-metadata-shell.sh
```

## 1. 토픽 관리

 - `토픽 생성`
```bash
# 토픽 생성
/opt/bitnami/kafka/bin/kafka-topics.sh \
--bootstrap-server my-kafka-headless:9092 \
--create --topic cli-test-topic \
--replication-factor 2 --partitions 3
```

 - `토픽 조회`
```bash
# 토픽 조회
/opt/bitnami/kafka/bin/kafka-topics.sh \
--bootstrap-server my-kafka-headless:9092 \
--list

# 토픽 상세 조회
/opt/bitnami/kafka/bin/kafka-topics.sh \
--bootstrap-server my-kafka-headless:9092 \
--describe --topic cli-test-topic

# 토픽 모든 설정 조회
/opt/bitnami/kafka/bin/kafka-configs.sh \
--bootstrap-server my-kafka-headless:9092 \
--describe --topic cli-test-topic --all
```

 - `토픽 설정 변경`
    - https://kafka.apache.org/documentation/#topicconfigs
    - retention.ms
        - 메시지를 얼마나 오랫동안 보관할지 설정
        - 메시지가 수신된 시점을 기준으로 시간이 지나면 해당 메시지를 포함한 로그 세그먼트 파일이 삭제됨
        - 토픽의 전체 로그 크기가 retention.bytes보다 클 경우에도 오래된 세그먼트는 삭제됨
    - segment.ms
        - 새로운 로그 세그먼트 파일을 생성하는 기준 시간 (기본값: 1시간)
        - 세그먼트 파일은 메시지를 일정 시간 동안 수집한 단위로 구성됨
        - 설정 시간이 지나면 강제로 새 세그먼트로 전환
        - 이는 compaction이나 retention 정책 적용에 영향을 줌
    - segment.bytes
        - 하나의 세그먼트 파일에 저장할 수 있는 최대 바이트 수 (기본값: 1GB, 1073741824 bytes)
        - 설정된 용량을 초과하면 새로운 세그먼트 파일로 전환
        - 파일 크기를 기준으로 세그먼트를 나누어 관리 성능 개선
```bash
# 설정 변경 : 보관 기간, 세그먼트 롤링 주기
# 설정 변경시에는 kafka-configs 도구를 이용한다.
/opt/bitnami/kafka/bin/kafka-configs.sh --bootstrap-server my-kafka-headless:9092 \
--alter --topic cli-test-topic \
--add-config retention.ms=1800000,retention.bytes=-1,segment.ms=600000

# 변경된 설정 확인
/opt/bitnami/kafka/bin/kafka-topics.sh \
--bootstrap-server my-kafka-headless:9092 \
--describe --topic cli-test-topic
```

 - `레플리카 검증`
    - 토픽 파티션의 레플리카드이 모두 같은 데이터를 갖고 있는지 확인
```bash
# Verification 프로세스 시작
/opt/bitnami/kafka/bin/kafka-replica-verification.sh \
--broker-list my-kafka-headless:9092 \
--topics-include cli-test-topic \
--report-interval-ms 5000
```

 - `레코드 삭제`
```bash
# 오프셋 삭제 구성 파일 생성
/opt/bitnami/kafka/bin/kafka-get-offsets.sh \
--bootstrap-server my-kafka-headless:9092 \
--topic cli-test-topic --time -1 \
| awk -F: 'BEGIN { ORS = ""; OFS = "," ; printf " { \"partitions\": [ " }
    { printf "%s{\"topic\": \"%s\", \"partition\": %s, \"offset\": %s}",
          separator, $1, $2, $3
      separator = ", "
    }
    END { printf " ], \"version\": 1 } " }
' > /tmp/delete-records.json

# 레코드 삭제
/opt/bitnami/kafka/bin/kafka-delete-records.sh \
--bootstrap-server my-kafka-headless:9092 \
--offset-json-file /tmp/delete-records.json

# 삭제 결과 확인
/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
--bootstrap-server my-kafka-headless:9092 \
--topic cli-test-topic --from-beginning
```

 - `토픽 삭제`
```bash
/opt/bitnami/kafka/bin/kafka-topics.sh \
--bootstrap-server my-kafka-headless:9092 \
--delete --topic cli-test-topic
```

## 2. 컨슈머 그룹 관리

프로듀서가 토픽에 보낸 메시지는 항상 파티션의 마지막에 추가하면 되기 때문에 오프셋을 별도로 관리할 필요가 없지만, 컨슈머는 유지 보수 혹은 장애로 인해 재시작할 경우 이전에 처리한 메시지는 건너뛸 필요가 있어 오프셋을 관리해야 한다.

컨슈머 오프셋은 컨슈머 그룹, 파티션별로 관리되며 컨슈머가 offset commit request를 보내고 브로커는 __consumer_offsets 토픽에 기록된다.

```bash
# 테스트 토픽 생성
/opt/bitnami/kafka/bin/kafka-topics.sh \
--bootstrap-server my-kafka-headless:9092 \
--create --topic consumer-group-test-topic \
--replication-factor 2 --partitions 6

# 테스트 메시지 전송
/opt/bitnami/kafka/bin/kafka-verifiable-producer.sh \
--bootstrap-server my-kafka-headless:9092 \
--topic consumer-group-test-topic --max-messages 1000

# 컨슈머(그룹) 생성
/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
--bootstrap-server my-kafka-headless:9092 \
--topic consumer-group-test-topic --from-beginning \
--group group1 \
--property print.timestamp=true,print.offset=true \
--property print.partition=true \
--property print.offset=true

# 컨슈머 그룹 확인
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--list

# 상세 정보 확인
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--describe --group group1

# 상태 확인
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--describe --group group1 --state

# 멤버 확인
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--describe --group group1 --members
```

 - `오프셋 리셋(특정 컨슈머 그룹에 대해서 오프셋 위치 변경)`
    - 현재 오프셋 이동
    - shift-by: 현재 오프셋에서 ±N 만큼 이동
    - by-duration: 현재 시간 기준으로 지정된 시간만큼 과거로 이동하여 해당 시점에 가장 가까운 오프셋으로 설정 (형식 PnDTnHnMnS (ISO-8601))
    - to-earliest: 해당 파티션의 가장 이른 오프셋으로 이동
    - to-latest: 해당 파티션의 가장 마지막 오프셋(다음 읽을 위치) 으로 이동. 컨슈머가 메시지를 처음부터 읽지 않고, 새로 들어오는 메시지만 읽도록 할 때 사용
    - to-datetime: 특정 시간(ISO-8601 또는 epoch millis)에 가장 가까운 오프셋으로 이동
    - to-offset: 지정한 오프셋 번호로 수동 설정
```bash
# 현재 오프셋에서 -100 만큼 이동
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--reset-offsets \
--group group1 \
--topic consumer-group-test-topic \
--shift-by -100 --execute # --execute 대신 --dry-run 옵션시 어디로 이동되는지 테스트(확인) 가능

# 15분전 오프셋으로 이동
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--reset-offsets \
--group group1 \
--topic consumer-group-test-topic \
--by-duration PT15M --execute

# 컨슈머 그룹 오프셋 삭제
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--delete-offsets \
--group group1 \
--topic consumer-group-test-topic

# 컨슈머 그룹 삭제
/opt/bitnami/kafka/bin/kafka-consumer-groups.sh \
--bootstrap-server my-kafka-headless:9092 \
--group group1 \
--delete
```

## 3. 무중단 업그레이드

카프카 버전은 클라이언트를 중단하지 않고 업그레이드하는 것이 가능하다. 업그레이드는 EOL이 만료되기 전에 하는 것이 좋으며, 심각한 보안 취약점에 대한 패치가 있는 경우에는 즉시 업그레이드 하는 것이 좋다.

 - `패치 버전 업그레이드 (3.3.1 -> 3.3.2)`
    - https://artifacthub.io/packages/helm/bitnami/kafka/20.0.6
```bash
# 현재 버전 확인
/opt/bitnami/kafka/bin/kafka-topics.sh --version

# 모니터링
/opt/bitnami/kafka/bin/kafka-console-consumer.sh \
--bootstrap-server my-kafka-headless:9092 \
--topic test-datagen-orders

# 업그레이드
helm upgrade my-kafka oci://registry-1.docker.io/bitnamicharts/kafka \
--version 20.0.6 --values my-kafka-override.yaml
```

 - `마이너 버전 업그레이드(3.3.2 -> 3.4.0)`
    - 업그레이드 방법: https://kafka.apache.org/34/documentation.html#upgrade
    - bitnami 커스텀 파라미터 설정: https://artifacthub.io/packages/helm/bitnami/kafka/21.4.6#setting-custom-parameters
    - 업그레이드시 inter.broker.protocol.version 설정을 이전 버전으로 설정하여 업그레이드 진행하고, inter.broker.protocol.version의 내용을 지우거나 최신 버전으로 바꿔서 업그레이드를 진행해야 한다. (2번 업그레이드)
```bash
# inter.broker.protocol.version 설정
cat > my-kafka-override.yaml <<EOF
replicaCount: 3
persistence:
  size: 10Gi
zookeeper:
  replicaCount: 3
  persistence:
    size: 5Gi
offsetsTopicReplicationFactor: 3
deleteTopicEnable: true
extraEnvVars:
- name: KAFKA_CFG_INTER_BROKER_PROTOCOL_VERSION
  value: "3.3"
EOF

# 업그레이드
helm upgrade my-kafka oci://registry-1.docker.io/bitnamicharts/kafka \
--version 21.4.6 --values my-kafka-override.yaml
```

### 카프카 버전 릴리즈

 - 버전 릴리즈 주기
    - https://cwiki.apache.org/confluence/display/KAFKA/Time+Based+Release+Plan
    - 1년에 3회 (4개월마다 릴리즈 목표)
    - 지난 1년간 버전에서 최신 버전으로 롤링 업그레이드 보장이 목표
 - 버전 릴리즈 플랜
    - https://cwiki.apache.org/confluence/display/KAFKA/Future+release+plan
 - 카프카 End Of Life
    - https://endoflife.date/apache-kafka
 - 추천 업그레이드 전략
    - 기본적으로 1년 1회 업그레이드 추천
    - 심각한 보안 취약점에 대한 패치가 있는 경우 최대한 신속하게 업그레이드해야 함
