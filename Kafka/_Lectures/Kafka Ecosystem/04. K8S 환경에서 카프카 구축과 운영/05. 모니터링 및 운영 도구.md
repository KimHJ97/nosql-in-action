# 모니터링 및 운영 도구

## 1. 모니터링 구성 개요

 - `브로커 모니터링`
    - 카프카 클러스터에서 가장 중요한 시스템
    - 모든 메시지는 브로커를 통해 처리됨
    - 올바르게 구성되면 일부 브로커가 중지되어도 카프카 클러스터는  서비스를 계속할 수 있음
    - 전체적인 서비스 성능은 저하될 수 있음
    - JMX 메트릭을 통해 모니터링 가능
 - `컨슈머 모니터링`
    - 카프카는 프로듀서가 토픽에 보낸 메시지를 컨슈머가 소비하여 처리하는 구조를 갖는 시스템
    - 따라서, 컨슈머 모니터링을 잘하면 메시지 흐름 전체를 확인할 수 있는 효과를 얻을 수 있음
    - - 컨슈머 모니터링의 주요 지표는 컨슈머 지연 값
    - __consumer_offsets 토픽 메시지를 통해 간접적으로 모니터링 가능
 - `주요 메트릭`
    - https://docs.confluent.io/platform/current/kafka/monitoring.html#kafka-monitoring-metrics-broker
    - https://www.slideshare.net/slideshow/apache-kafka-metrics-123663954/123663954
    - https://www.site24x7.com/learn/apache-kafka-performance-monitoring.html
    - __ActiveControllerCount__: 카프카 클러스터에서 컨트롤러 개수가 반드시 1이어야 함
    - __UnderMinIsrPartitionCount__, __UnderReplicatedPartitions__, __UnderMinIsr__: 복제가 원활하게 수행되지 않고 있음
    - __OfflinePartitionsCount__: 브로커 중지 등의 이유로 사용할 수 없는 파티션이 있음
    - __IsrShrinksPerSec__, __IsrExpandsPerSec__: 수치가 높으면 네트워크가 불안정하거나 트래픽이 너무 많을 수 있음
    - __TotalTimeMs__: roduce, FetchConsumer, FetchFollower latency
        - 메시지 발행 지연 값이 너무 크면 최적화가 필요할 수 있음
        - FetchConsumer, FetchFollower 지연 값은 상황에 따라 왜곡될 수 있음

## 2. 메트릭 수집과 시각화

### 2-1. 메트릭 익스포터 구성

 - https://artifacthub.io/packages/helm/bitnami/kafka/21.4.6#metrics-parameters
```bash
# 클러스터 구성 변경
cat > my-kafka-override.yaml <<EOF
replicaCount: 3
persistence:
  size: 10Gi
zookeeper:
  replicaCount: 3
  persistence:
    size: 5Gi
offsetsTopicReplicationFactor: 3
deleteTopicEnable: true
auth:
  interBrokerProtocol: sasl
  clientProtocol: sasl
  sasl:
    interBrokerMechanism: scram-sha-512
authorizerClassName: kafka.security.authorizer.AclAuthorizer
extraEnvVars:
- name: KAFKA_CFG_DELEGATION_TOKEN_SECRET_KEY
  value: very-very-secret-key
allowEveryoneIfNoAclFound: false
superUsers: User:admin;User:devops
metrics:
  jmx:
    enabled: true
EOF

# 변경 사항 적용
helm upgrade my-kafka oci://registry-1.docker.io/bitnamicharts/kafka \
--version 21.4.6 --values my-kafka-override.yaml

# 구성 변경 확인
kubectl exec my-kafka-0 -- bash -c "curl -v localhost:5556/metrics"
```

### 2-2. 메트릭 수집 시스템 구성 (Prometheus)

 - Prometheus는 널리 사용되고 있는 메트릭 수집 시스템이다.
 - JMX Exporter도 프로메테우스 에코에 속한 애플리케이션이다.
    - node-exporter, jmx exporter, pushgateway, 기타
 - Kafka는 기본적으로 JMX 메트릭을 저장한다. metric.reporters에 메트릭 저장을 추가할 수 있다. JMX EXPORTER로 저장된 JMX 메트릭을 다른 곳에서 가져갈 수 있다. Prometheus에서 JMX EXPORTER에서 노출한 메트릭 정보를 수집한다.
    - Kafka는 기본적으로 JMX(Java Management Extensions) 를 통해 메트릭 정보를 노출합니다. Kafka 자체가 Java 애플리케이션이기 때문에 JMX는 JVM 기반 모니터링을 위한 표준적인 방법으로 사용된다.
    - JMX Exporter는 Kafka 같은 Java 애플리케이션이 노출하는 JMX 메트릭을 Prometheus 형식으로 변환해주는 도구다.
    - JMX Exporter는 Prometheus 프로젝트의 서브 컴포넌트로, JVM 기반 앱의 JMX 메트릭을 HTTP 엔드포인트를 통해 Prometheus가 스크랩(pull) 할 수 있게 해준다.
 - 전체 구성
    - 1. Kafka 등 JVM 애플리케이션 → JMX로 메트릭 노출
    - 2. JMX Exporter Agent → JMX 데이터를 Prometheus 포맷으로 변환
    - 3. Prometheus → 해당 포맷을 HTTP로 스크랩
    - 4. Grafana → Prometheus에서 가져온 데이터 시각화
```bash
# repo 추가
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# prometheus 설치 구성
cat > my-prometheus-override.yaml <<EOF
kube-state-metrics:
  enabled: false
prometheus-node-exporter:
  enabled: false
prometheus-pushgateway:
  enabled: false
EOF

# prometheus 설치
helm install my-prometheus prometheus-community/prometheus \
--values my-prometheus-override.yaml
```

 - `메트릭 수집 구성`
    - https://artifacthub.io/packages/helm/prometheus-community/prometheus#configuration
```bash
cat >> my-kafka-override.yaml <<EOF
podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/path: /metrics
  prometheus.io/port: "5556"
EOF

# 변경 사항 적용
helm upgrade my-kafka oci://registry-1.docker.io/bitnamicharts/kafka \
--version 21.4.6 --values my-kafka-override.yaml

# 프로메테우스 외부 접속 포트 포워드
kubectl port-forward svc/my-prometheus-server 80 --address {ip}
```

### 2-3. 메트릭 시각화 구성

```bash
# repo 추가
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# Grafana 설치
helm install my-grafana grafana/grafana

# 관리자 패스워드 확인
kubectl get secret --namespace default my-grafana -o jsonpath="{.data.admin-password}" \
| base64 --decode ; echo

# 그라파나 외부 접속 포트 포워드
kubectl port-forward svc/my-grafana 80 --address {ip}

# 데이터 소스 추가

# 샘플 대시보드 추가
# https://grafana.com/grafana/dashboards/12483-kubernetes-kafka/
```

## 3. 컨슈머 지연 모니터링 도구

### 3-1. 컨슈머 지연

 - 컨슈머가 아직 처리하지 않은 메시지 개수
 - 특정 토픽 파티션, 컨슈머 그룹 별로 측정 가능
 - kafka-consumer-groups.sh 도구를 이용하여 확인 가능
 - 컨슈머 그룹이 정상적으로 작동하는지 확인할 수 있는 주요 지표

### 3-2. 컨슈머 지연 모니터링 도구

 - Burrow: https://github.com/linkedin/Burrow
    - 링크드인에서 개발한 오픈소스 카프카 컨슈머 지연 모니터링 도구
    - 컨슈머 지연을 지속해서 모니터링하고 평가하는 기능 제공
 - Burrow-modified: https://github.com/spithainc/Burrow-modified
    - `notifier` 기능을 제외 - `zookeeper` 기능 제외
    - `PLAIN`, `OAUTHBEARER`, `GSSAPI` 인증 추가 지원
 - `StatusNotFound(=0)`
    - 파티션에는 적용 안 됨
    - 컨슈머 그룹 찾을 수 없음
 - `StatusOK(=1)`
    - 파티션이 양호한 상태
    - 컨슈머 그룹의 모든 파티션이 양호한 상태
 - `StatusWarning(=2)`
    - 파티션이 지연되고 있음을 나타내며, 진행 중이지만 더 뒤처지고 있음
    - 그룹의 경우 하나 이상의 파티션이 지연되고 있음
 - `StatusError(=3)`
    - 파티션에는 적용 안 됨
    - 그룹에 중지, 정지 또는 되감기 상태인 파티션이 하나 이상 있음
 - `StatusStop(=4)`
    - 컨슈머가 해당 파티션에 대해 일정 시간 동안 오프셋을 커밋하지 않았으며 지연이 0이 아닌 상태
    - 그룹 상태에는 사용되지 않음
 - `StatusStall(=5)`
    - 컨슈머가 파티션에 대한 오프셋을 커밋하고 있지만 증가하지 않고 있으며 지연이 0이 아닌 상태
    - 그룹 상태에는 사용되지 않음
 - `StatusRewind(=6)`
    - 컨슈머가 파티션에 대해 이전 오프셋보다 작은 오프셋을 커밋했음을 나타냄
    - 그룹 상태에는 사용되지 않음

### 3-3. 모니터링 도구 구성

 - `지연 모니터 설정 생성`
```bash
cat > burrow-configmap.yaml <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: burrow-lag-monitor-config
data:
  burrow.yaml: |
    httpserver:
      default:
        address: ':8000'
    client-profile:
      my-kafka:
        kafka-version: 3.4.0
        sasl: "my-kafka"
        client-id: burrow-lag-monitor
    sasl:
      my-kafka:
        mechanism: "SCRAM-SHA-512"
        username: "devops"
        password: "devops-secret"
        handshake-first: true
    cluster:
      my-kafka:
        class-name: kafka
        servers:
          - 'my-kafka-headless:9092'
        client-profile: my-kafka
        topic-refresh: 60
        offset-refresh: 30
        groups-reaper-refresh: 30
    consumer:
      my-kafka:
        class-name: kafka
        cluster: my-kafka
        servers:
          - 'my-kafka-headless:9092'
        client-profile: my-kafka

EOF

kubectl apply -f burrow-configmap.yaml
```

 - `지연 모니터링 Deployment 및 서비스 생성`
```bash
cat > burrow-deployment.yaml <<EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    spitha.io: burrow-lag-monitor
  name: burrow-lag-monitor
spec:
  replicas: 1
  selector:
    matchLabels:
      spitha.io: burrow-lag-monitor
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        spitha.io: burrow-lag-monitor
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: /metrics
        prometheus.io/port: "8000"
    spec:
      containers:
      - image: spitharepo/burrow:latest
        name: burrow-lag-monitor
        volumeMounts:
        - name: config
          mountPath: "/etc/burrow"
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: burrow-lag-monitor-config
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  name: burrow-lag-monitor-service
spec:
  selector:
    spitha.io: burrow-lag-monitor
  ports:
    - protocol: TCP
      port: 8000
EOF

kubectl apply -f burrow-deployment.yaml
```

 - `데이터 및 메트릭 확인`
```bash
# 데이터 확인
kubectl exec my-kafka-client -- \
sh -c "curl burrow-lag-monitor-service:8000/v3/kafka" \
| jq

kubectl exec my-kafka-client -- \
sh -c "curl burrow-lag-monitor-service:8000/v3/kafka/my-kafka/consumer/test-consumer-group" \
| jq

# 메트릭 확인
kubectl exec my-kafka-client -- \
sh -c "curl burrow-lag-monitor-service:8000/metrics | grep test-"
```

## 4. WEB 관리 도구 구성 및 사용

### 4-1. 웹 관리 도구

 - kafka-ui: https://github.com/provectus/kafka-ui
 - akhq: https://github.com/tchiotludo/akhq
 - CMAK: https://github.com/yahoo/CMAK

### 4-2. UI for Apache Kafka 설치

```bash
# repo 추가
helm repo add kafka-ui https://provectus.github.io/kafka-ui-charts

# 관리 대상 클러스터 설정
cat > my-kafka-ui-override.yaml <<EOF
yamlApplicationConfig:
  kafka:
    clusters:
      - name: my-kafka
        bootstrapServers: my-kafka-headless:9092
        properties:
          security:
            protocol: SASL_PLAINTEXT
          sasl:
            mechanism: SCRAM-SHA-512
            jaas:
              config: org.apache.kafka.common.security.scram.ScramLoginModule required username="devops" password="devops-secret";
  auth:
    type: disabled
  management:
    health:
      ldap:
        enabled: false
EOF

# UI for Apache Kafka 설치
helm install my-kafka-ui kafka-ui/kafka-ui --values my-kafka-ui-override.yaml

# 외부 접속 포트 포워드
kubectl port-forward svc/my-kafka-ui 80 --address 172.31.24.2
```
