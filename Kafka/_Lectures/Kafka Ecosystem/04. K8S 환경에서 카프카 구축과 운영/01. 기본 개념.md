# 기본 개념

 - 다양한 카프카 배포 방법
 - k8s에 카프카 배포 방법
 - 대표적인 컨테이너 배포판
 - 완전 관리형 카프카 서비스

## 1. 다양한 카프카 배포 방법

### 1-1. 다양한 소프트웨어 구동 환경과 장단점

소프트웨어를 구동하는 데는 BareMetal, Virtual Machine, Container 등의 환경이 있다. 카프카도 다른 소프트웨어와 마찬가지로 BareMetal, Virtual Machine, Container 등의 환경에 배포하여 사용할 수 있다.

 - `BareMetal`
    - 카프카에서 단독으로 HW 시스템을 사용
    - 매우 많은 메시지 양을 처리할 필요가 있는 경우 사용할 수 있음
    - 장점
        - 높은 사양의 H2를 성능 저하 없이 단독으로 사용할 수 있음
        - Multiple AZ 등 FAIL-OVER 관련 환경 구성이 쉬움
            - 랙 분산, L2 네트워크 분리 등
    - 단점
        - 필요한 사양보다 과한 H2가 할당될 수 있음
        - Scale-UP이 어려울 수 있음
            - 스토리지 확장, CPU 추가
 - `Virtual Machine`
    - 운영 환경은 Bare Metal과 큰 차이 없음
    - 일반적으로 가장 적합한 방법
    - 장점
        - Scale-Up, Scale-Out이 상대적으로 쉬움
        - 다른 애플리케이션의 영향없이 시스템을 단독으로 사용할 수 있음
     - 단점
        - Fail-Over 구성을 고려하여 VM을 적절하게 배치해야 함
 - `Container`
    - k8s와 같은 환경에 카프카를 구축하여 운영하는 사례가 많아지고 있음
    - 장점
        - Scale Out이 쉬운편
        - 버전 업그레이드 등의 유지보수가 쉬움
    - 단점
        - 다른 애플리케이션과 자원을 경쟁할 수 있음
    - 최근 컨테이너 배포에 대한 요구가 많아짐
        - Cloud Native: MSA, DevOps, Automation, Container, Serverless
        - Microservice 애플리케이션 간의 메시징 허브로 Kafka를 채택하는 경우가 많음
        - 애플리케이션 운영 및 관리 플랫폼으로 k8s를 채택하는 사례가 많음
            - On-Perm: VM 가상화 단계를 건너뛰고 BareMetal에 바로 k8s 구축
                - 솔루션 중복 투자 배제
                - 운영 관리 단순화
            - Cloud: EKS, GKE 등의 컨테이너 서비스 이용

### 1-2. 카프카 시스템 요구 사양

카프카 클러스터를 구성하기 위해 필요한 사양은 정답이 없으며 다양한 요소가 고려되어야 한다.

 - 카프카 클러스터에 입력되는 메시지 양
 - 메시지의 보관 기간
 - 토픽/파티션의 개수
    - 주키퍼 클러스터의 경우 브로커당 최대 4,000개/클러스터당 최대 200,000개 정도의 파티션을 사용가능한 것으로 알려져 있다.
 - 카프카 클러스터에서 읽어가는 메시지 양
    - 네트워크 대역폭 ≥ 들어오는 메시지 양 * 복제본 수 + 나가는 메시지 양
 - TLS 사용 여부
    - 더 많은 CPU 자원이 필요
        - 메시지 암복호화
        - Zero Copy 사용할 수 없음
 - 카프카 공식 문서 요구 시스템 사양
    - https://kafka.apache.org/documentation/#hwandos
    - 메모리는 많을 수록 좋다.
        - 30초 버퍼를 위한 메모리 요구량 = 30 * write_throughput
    - 디스크는 빠르고 많을 수록 좋다.
        - 디스크 개수가 많으면 병렬처리로 인한 IO 성능이 좋아진다.
        - 개별 디스크 VS RAID
            - 개별 디스크는 쓰기 성능이 더 좋지만 관리가 어렵다.
            - RAID는 디스크 장애에 강하지만 쓰기 성능이 저하되고 가용 공간이 줄어든다.
            - 토픽 복제본을 구성하여 RAID가 필요 없을 수 있지만, 디스크 장애가 발생하면 데이터 복구에 많은 자원이 소모될 수 있다..
                - 토픽 복제본을 통한 복구: 카프카 클러스터의 다른 복제본에서 데이터를 복구해야 하므로 네트워크 자원 소모가 많을 수 있다.
                - RAID를 통한 복구: RAID 구성에서 자체적으로 데이터를 복구하므로 네트워크 자원 소모는 없지만 복구하는 동안 디스크 쓰기 성능 저하로 카프카 성능에 영향을 줄 수 있다.
 - 메모리
    - Java Heap: Max 6GB
    - 나머지는 Write Cache로 사용. 메모리 32GB일 경우 28 ~ 30GB 캐시 확보 가능
    - 32GB 미만은 권장하지 않음
 - CPU
    - 카프카는 CPU 작업이 많지는 않으나 TLS를 이용하는 경우 암복호화 작업으로 인해 CPU를 더 많이 사용하게 된다.
    - 빠른 CPU 보다는 더 많은 코어가 유리하다.
 - 네트워크
    - 카프카는 네트워크에서 메시지를 주고받는 시스템이므로 빠른 네트워크가 요구된다.

### 1-3. 적절한 시스템 사양

 - 다다익선
 - 아마존 모범 사례
    - https://docs.aws.amazon.com/ko_kr/msk/latest/developerguide/bestpractices.html
    - kafka.t3.small 인스턴스로 브로커당 300개의 파티션 사용 가능
    - 2Core / 2GB T3 인스턴스
    - 네트워크 사양 제한이 있기는 하지만, 10MB/s의 데이터는 충분히 처리 가능
        - 일 1TB -> 11.5MB/s
        - IoT 단말이 1초당 1KB 메시지를 1개씩 보낸다고 하면, 11,500대의 단말이 보내는 메시지 처리 가능
    - 컨텐이너로 배포하는 경우 더 적은 리소스 할당이 가능하다.
        - OS가 사용하는 CPU, 메모리를 제외하고 순수하게 카프카가 사용하는 리소스만 요청
        - 페이지 캐시는 확보하는 것이 좋음
            - 메모리 요구량 = JVM Heap + Page Cache
        - 다른 워크로드와 자원 경쟁을 하지 않도록 자원 요구량을 설정하는 것이 좋다.

## 2. k8s에 카프카 배포 방법

### 2-1. k8s 워크로드

Kubernetes 클러스터에서 애플리케이션이 어떻게 실행되는지를 정의한 리소스입니다. 즉, Pod를 어떤 방식으로 생성하고 운영할지에 대한 정책과 스펙을 가진 리소스를 워크로드라고 부른다.

 - 워크로드는 Kubernetes에서 어떤 애플리케이션이 어떻게 실행될지를 정의한 객체
 - Pod 자체는 워크로드가 아니고, 워크로드가 생성하고 관리하는 대상
 - 다양한 워크로드 종류는 각각 다른 운영 목적에 맞게 사용됨

### 2-2. k8s 워크로드 리소스 종류

Kubernetes에서는 파드를 직접 관리할 필요가 없도록 여러 가지 워크로드 리소스를 정의한다.

 - `Pod`
    - 가장 기본 단위. 컨테이너 1개 또는 여러 개를 묶은 실행 단위
 - `Deployment`
    - 무중단 배포, 스케일링, 롤백 등을 지원하는 가장 일반적인 워크로드
    - ReplicaSet을 관리하고 업데이트하는 데 사용됨
    - 여러 개의 Pod를 생성하고 관리할 수 있으며, 롤링 업데이트 및 롤백과 같은 기능을 제공
 - `StatefulSet`
    - 상태 유지가 필요한 워크로드. 각 Pod에 고유 ID와 영구 저장소 할당
    - Pod의 순서화된, 고유한 네트워크 식별자와 함께 배포됨
    - 카프카와 같이 상태를 유지해야 하는 애플리케이션을 배포하는 데 사용됨 (DB, Kafka, Zookeeper)
    - 카프카는 스토리지에 메시지 로그 파일을 저장하는 구조로 원활한 작동을 위해 PV(Persistent Volume)이 필요하므로 스테이트풀셋이 적합한 형태임
        - PV를 사용하지 않으면 브로커 장애 혹은 업데이트 등의 이유로 재시작했을 때 데이터가 유실될 수 있음
 - `DaemonSet`
    - 클러스터의 모든 노드에 1개씩 Pod를 배포
    - 클러스터의 모든 워크 노드에 Pod를 배포하는 데 사용됨
    - 모든 노드에서 실행되어야 하는 애플리케이션에 적합함 (로그 수집기, 모니터링 에이전트)
 - `Job / CronJob`
    - 실행 완료 후 중단되는 작업을 정의
    - CronJob은 스케줄에 따라 반복

### 2-3. k8s 워크로드 배포 방법들

 - `kubectl`
    - __YAML 파일로 정의한 워크로드를 수동 배포__
    - k8s에 대한 높은 이해도가 필요하고 개발 역량이 필요함
 - `Helm Chart`
    - __K8s용 패키지 매니저 (Chart로 워크로드 정의)__
    - Helm은 Kubernetes 애플리케이션을 패키징하고 배포하기 위한 도구
    - 미리 정의된 구성 및 설정을 사용하여 워크로드를 손쉽게 배포 가능
    - 설정 파일이 별도로 구성되어 있어 간편하게 변경 가능
    - 아티팩트 허브(https://artifacthub.io/)에서 다양한 애플리케이션에 대한 검증된 차트를 받아 사용할 수 있음
    - 팀원 간 설정 값 공유, 환경별 값 분리 등 구성 관리가 용이
 - `Kustomize`
    - __YAML 오버레이 방식으로 환경별 설정을 분리 관리__
    - kubectl과 통합되어 기본적으로 사용 가능 (kubectl apply -k)
    - 공통 리소스를 base/에 정의하고, overlays/ 디렉토리를 통해 dev/prod 등의 환경별 설정을 쉽게 분리할 수 있음
    - Helm처럼 템플릿 언어를 사용하지 않고 순수 YAML로 선언적 구성 유지 가능
    - 복잡한 값 설정보다는 단순 오버레이에 적합
    - CI/CD에 통합하기도 좋고, Helm보다 학습 곡선이 낮은 편
 - `GitOps (ArgoCD, Flux)`
    - __Git 저장소에 선언된 상태를 클러스터와 자동 동기화하는 방식__
    - 애플리케이션의 배포 상태를 Git이 “단일 진실의 원천(source of truth)”으로 관리함
    - ArgoCD나 Flux 같은 GitOps 도구가 Git 저장소를 감시하다가 변경사항이 생기면 자동으로 클러스터 상태를 업데이트
    - 배포 히스토리, 변경 이력 추적, 롤백 등이 Git 커밋만으로 가능
    - DevOps/SRE 팀 중심의 운영 환경에서 필수로 자리잡는 트렌드
    - 복잡한 환경일수록 안정적이고 예측 가능한 배포 체계를 만들 수 있음
 - `CI/CD 연동 (Jenkins, GitHub Actions, GitLab CI 등)`
    - 코드 변경 → 빌드 → 테스트 → 배포까지 자동화
    - 워크로드 정의는 Helm, Kustomize, YAML 등 다양한 방식으로 가능
    - 애플리케이션 코드와 K8s 설정이 하나의 파이프라인으로 연결되어 배포 일관성 확보
    - Slack 알림, 테스트 자동화, 버전 태깅 등과 연계 가능
 - `Operator 기반 배포`
    - __특정 워크로드에 특화된 Custom Resource + 자동 운영 도구__
    - Kafka, Elasticsearch, Redis 등 상태를 갖는 애플리케이션을 안전하게 배포하고 관리하기 위해 Operator를 사용
    - 예시: Strimzi Kafka Operator, Prometheus Operator 등
    - 클러스터 내에서 자동 스케일링, 리밸런싱, 장애 복구 등 도메인 지식을 내장한 방식
    - 초기 설정은 복잡할 수 있지만, 운영 자동화에 매우 강력한 방식

## 3. 대표적인 컨테이너 배포판

### 3-1. 무료로 사용할 수 있는 컨테이너 이미지

 - `Confluent Kafka (Community)`
    - 컨플루언트는 LinkedIn에서 카프카를 개발했던 개발자들이 설립한 회사
    - 오픈소스 카프카 개발 커뮤니티에서 매우 중요한 역할을 하고 있음
    - 커뮤니티 버전의 컨테이너 이미지를 다양하게 제공하고 있음
    - k8s에 카프카를 배포하기 위한 operator를 제공하고 있음
 - `Bitnami Kafka`
    - 다양한 애플리케이션의 컨테이너 이미지를 제공
    - 현재 vmware inc. 에서 bitnami 이미지를 개발 및 제공하고 있음
    - 다양한 환경에 설치할 수 있는 이미지 제공
    - public cloud(AWS, GCP, AZURE), Docker, K8S, VM(OVA image)
 - `strimzi`
    - 카프카 클러스터를 K8S 환경에 배포하기 위한 CNCF의 샌드박스 프로젝트
    - confluent와 마찬가지로 K8S operator를 이용하여 카프카 클러스터를 구성 배포하고 관리
    - StatefulSet 대신 StrimziPodSet이라는 커스텀 리소스를 사용함

#### Bitnami Kafka

 - Bitnami Helm Chart와 완벽 호환
 - 최신 Kafka 릴리즈 반영 빠름
 - 보안 설정 및 환경변수 깔끔함
```bash
docker run -d --name kafka \
  -e KAFKA_BROKER_ID=1 \
  -e KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 \
  -e ALLOW_PLAINTEXT_LISTENER=yes \
  -p 9092:9092 \
  bitnami/kafka:latest
```

#### Confluent Community Image

 - ksqlDB, Control Center, Schema Registry 등 Confluent 구성요소와 연계 쉬움
 - Confluent Platform을 일부 포함하고 있어 컨테이너가 큼
 - 오픈소스 라이선스(CPL)에 민감한 경우 주의 필요
```bash
docker run -d --name kafka \
  -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -p 9092:9092 \
  confluentinc/cp-kafka:latest
```

 - `docker-compose.yml`
```yml
version: '3'

services:
  zookeeper:
    image: bitnami/zookeeper:latest
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: bitnami/kafka:latest
    ports:
      - "9092:9092"
    environment:
      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092
```

#### Redpanda (Zookeeper 없이 가볍게)

 - Kafka API 100% 호환
 - 매우 빠르고 경량
 - Zookeeper 없음 → 단일 프로세스로 매우 간단
 - Kafka Native 기능 일부 미지원 (특수한 경우)
```bash
docker run -d --name redpanda \
  -p 9092:9092 \
  -p 9644:9644 \
  vectorized/redpanda \
  redpanda start --overprovisioned --smp 1 --memory 1G --reserve-memory 0M --node-id 0 --check=false
```

### 3-2. 공식 컨테이너 이미지

KIP-1028은 Apache Kafka에 대한 __Docker 공식 이미지(Docker Official Image, DOI)__ 를 도입하는 것을 목표로 합니다. 이 제안은 이전의 KIP-975를 기반으로 하며, Kafka의 각 릴리스에 대해 Docker 공식 이미지를 제공하는 것을 제안합니다. 

 - Docker Hub: https://hub.docker.com/r/apache/kafka
 - 주소: https://cwiki.apache.org/confluence/display/KAFKA/KIP-1028%3A%2BDocker%2BOfficial%2BImage%2Bfor%2BApache%2BKafka
 - __Docker 공식 이미지 제공__: 각 Kafka 릴리스에 대해 Docker 공식 이미지를 제공하여 사용자들이 신뢰성 있고 표준화된 이미지를 사용할 수 있도록 합니다.​
 - __보안 및 투명성 강화__: Docker 공식 이미지는 엄격한 검토 과정을 거치며, 보안 및 투명성 측면에서 이점을 제공합니다.​
 - __사용자 접근성 향상__: Docker Hub에서 공식 이미지를 제공함으로써, 새로운 사용자들이 Kafka를 쉽게 발견하고 사용할 수 있도록 합니다.​

<br/>

Apache Kafka는 그전까지는 공식 Docker 이미지를 제공하지 않았고, 사용자들은 Confluent의 커뮤니티 이미지 (confluentinc/cp-kafka), Bitnami의 이미지 (bitnami/kafka), Wurstmeister 이미지 (wurstmeister/kafka)를 사용하였다.

이 이미지들은 편리했지만, 공식 Kafka 프로젝트의 표준 구현과 완전히 일치하지는 않았고, 보안, 버전 동기화, 설정 명세 등에서 혼란이 있을 수 있었다.

 - `공식 이미지 제공 시점`
    - 최초 제공 버전: apache/kafka:3.7.0
    - 릴리스 날짜: 📅 2024년 2월 27일

 - `구성 방법`
    - Kafka를 __공식 이미지 apache/kafka:3.7.0__ 으로 구성할 때는, Kafka가 기본적으로 Zookeeper 없는 KRaft 모드로 구동된다.
```bash
# Kafka 브로커 시작
docker run -d --name broker apache/kafka:latest
docker exec --workdir /opt/kafka/bin/ -it broker sh
./kafka-topics.sh --bootstrap-server localhost:9092 --create --topic test-topic
./kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test-topic
./kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning

# 기본 브로커 구성 재정의
# KAFKA_PROCESS_ROLES: broker, controller 또는 둘 다 (예: broker,controller)
# KAFKA_NODE_ID: 고유 노드 ID (숫자)
# KAFKA_CONTROLLER_QUORUM_VOTERS: 클러스터 구성원 정의: nodeId@host:port 형식
# KAFKA_LISTENERS: 브로커가 수신할 프로토콜 및 포트 (예: PLAINTEXT://:9092)
# KAFKA_ADVERTISED_LISTENERS: 외부에서 접속 가능한 주소 (예: PLAINTEXT://localhost:9092)
# KAFKA_LOG_DIRS: 로그 파일 저장 경로
# KAFKA_CONTROLLER_LISTENER_NAMES: 컨트롤러 리스너 이름 지정 (예: CONTROLLER)

docker run -d  \
  --name broker \
  -e KAFKA_NODE_ID=1 \
  -e KAFKA_PROCESS_ROLES=broker,controller \
  -e KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \
  -e KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093 \
  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
  -e KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \
  -e KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \
  -e KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0 \
  -e KAFKA_NUM_PARTITIONS=3 \
  apache/kafka:latest
```

## 4. 완전 관리형 카프카 서비스

완전 관리형 카프카 서비스는 카프카 클러스터를 직접 구축할 필요 없이 클라우드 서비스를 통해 카프카 서비스를 이용하는 방식을 말한다.

 - Kafka를 직접 설치하거나 운영하지 않아도 됨
 - 토픽 생성, 메시지 전송/수신만 하면 됨
 - SLA, 자동 스케일링, 보안, 백업 등은 서비스 제공자가 처리
 - `장점`
    - 웹 UI를 이용해 간편하게 카프카 클러스터 구성
    - CSP의 다양한 서비스와 간편한 연계
    - 기술 내재화 없이 운영 및 유지 관리 가능
    - 클러스터 확장, 업그레이드, 스토리지 확장 등이 쉬움
 - `단점`
    - 운영 비용이 상대적으로 높다
    - 일방적인 시스템 유지 보수 작업
    - CSP 제공 타 서비스를 연계하지 않는 경우 큰 장점이 없음
 - `주의점`
    - 비용: 자체 구축보다 비용이 더 높을 수 있음 (특히 대규모 사용 시)
    - 벤더 락인: 특정 클라우드 서비스에 종속될 수 있음
    - 커스터마이징 제약: JVM 설정, 특정 Kafka 플러그인 등 자유도가 낮을 수 있음
    - 네트워크 구성: 퍼블릭/프라이빗 서브넷, VPC Peering 등 네트워크 지식 필요

| 항목                        | 일반 Kafka                     | 완전 관리형 Kafka                          |
|---------------------------|------------------------------|-------------------------------------------|
| 브로커 설치 및 유지보수        | ❗️직접 해야 함                    | ✅ 제공사에서 자동으로                       |
| Zookeeper/KRaft 구성       | 필요                           | ✅ 자동 구성됨                              |
| 클러스터 업그레이드          | 직접 계획, 테스트 필요              | ✅ 무중단 자동 업그레이드                    |
| 모니터링 및 경보             | Prometheus, Grafana 구성 필요 | ✅ 기본 제공                                |
| 보안 설정 (TLS, 인증 등)     | 직접 설정                        | ✅ 기본 활성화                              |
| 백업/복구                   | 스크립트 필요                     | ✅ 지원 또는 자동 백업                       |
| Auto-scaling              | 수동 설정 필요                    | ✅ 사용량에 따라 자동 확장                  |


### 4-1. 완전 관리형 Kafka 서비스 종류

| 서비스                      | 제공사                      | 주요 특징                                                                 |
|---------------------------|-----------------------------|--------------------------------------------------------------------------|
| Confluent Cloud           | Confluent (Kafka 창시자 회사) | Kafka + Schema Registry + ksqlDB 포함, 가장 기능이 풍부함                    |
| Amazon MSK (Managed Streaming for Kafka) | AWS                         | AWS 네이티브 통합, IAM 인증, EBS 기반 스토리지                            |
| Azure Event Hubs for Kafka | Microsoft                    | Kafka API와 호환되는 Event Hub, Azure 서비스와 통합됨                     |
| Aiven for Apache Kafka    | Aiven                        | 멀티클라우드 지원, Terraform 연동, 자동 백업                              |
| Redpanda Cloud            | Redpanda                     | Zookeeper 없이 Kafka 호환, 초고속 퍼포먼스                                |
| Instaclustr Kafka         | DataStax                     | 오픈소스 친화적, SLA 중심, 관리형 Kafka 전문 서비스                        |

