# Kafka Multi Cluster

Kafka Multi Cluster는 하나의 Kafka 클러스터로 모든 요구 사항을 처리하기 어렵거나, 지리적 분산, 고가용성, 부하 분산, 데이터 격리 등을 이유로 여러 개의 Kafka 클러스터를 사용하는 아키텍처를 말합니다.

Kafka Multi Cluster는 두 개 이상의 Kafka 클러스터를 운영하여 데이터 스트리밍 시스템을 구성하는 방식입니다. 각 클러스터는 독립적으로 운영되며, 특정 목적이나 지역, 부서, 또는 서비스별로 나눠질 수 있습니다.

 - 지리적 분산: 여러 지역(예: 한국-미국)에 걸쳐 데이터 센터가 존재할 경우
 - 격리: 팀이나 서비스 단위로 Kafka 클러스터를 분리해서 장애 전파를 방지
 - 확장성: 단일 클러스터로는 처리량 한계가 있을 때
 - 보안/규제: 데이터가 특정 지역을 벗어나면 안 되는 경우

## 1. Multi Cluster 구성 방식

 - `Independent Clusters`
    - 클러스터 간 연결 없이 완전 독립적으로 운영
    - 각각의 Kafka 클러스터가 완전한 책임을 가짐
    - 📌 장점: 장애 격리, 구성 단순
    - ⚠️ 단점: 클러스터 간 데이터 연동 어려움
 - `Cluster Linking (Kafka 공식 기능)`
    - Kafka 2.4 이후 도입된 기능으로, 두 Kafka 클러스터 간의 데이터 복제를 자동으로 구성할 수 있음.
    - 소스 클러스터 → 타겟 클러스터로 topic을 복제
    - 실시간 복제가 가능
    - ACL, consumer group 등은 별도로 관리됨
    - 📌 장점:운영이 간단하고 실시간 데이터 복제 가능, Kafka-native 기능으로 안정성 보장
    - ⚠️ 단점: 제한된 기능 (예: 필터링, 변환 등은 없음)
 - `MirrorMaker 2`
    - Apache Kafka에서 제공하는 데이터 복제 도구
    - Confluent에서 개선된 버전 제공
    - Kafka Connect 기반으로 동작
    - Topic, consumer group, offset 등을 복제 가능
    - 📌 장점: 유연한 설정 가능 (필터링, 라우팅 등), 다수의 클러스터 연동 가능
    - ⚠️ 단점: 설정이 복잡하고 운영 부담 존재

## 2. Multi Cluster 아키텍처

| 아키텍처 유형          | 지리적 분산 | DR   | 격리 | 실시간 복제 | 복잡도     |
|----------------------|------------|------|------|-------------|------------|
| Active-Active        | ✅         | ✅   | ❌   | ✅          | 🔥 높음    |
| Active-Passive       | ✅         | ✅   | ❌   | 보통        | 🟡 중간    |
| Geo-Partitioned      | ✅         | ❌   | ❌   | 일부        | 🔥 높음    |
| Domain/Service 기반 | ❌         | ❌   | ✅   | 보통        | 🟡 중간    |


 - `Active-Active Cluster`
    - 두 개 이상의 클러스터가 동시에 데이터를 처리하며 서로 연동되는 구조
    - 여러 지역에 위치한 Kafka 클러스터들이 동등한 역할을 수행
    - 서로 데이터를 양방향으로 복제
    - 보통 MirrorMaker 2나 Cluster Linking을 사용
    - 📌 장점: 지리적 이중화, 지역 간 로컬 처리 가능 (latency 감소)
    - ⚠️ 단점: 중복 데이터 및 데이터 충돌 문제 발생 가능, 복잡한 토픽/Consumer group 동기화 필요

 - `Active-Passive (DR/Backup)`
    - 하나의 클러스터만 운영하고, 나머지는 백업용으로 대기하는 구조
    - Primary 클러스터가 모든 데이터를 처리
    - Secondary 클러스터는 주기적으로 복제받음 (MirrorMaker 또는 Cluster Linking)
    - 📌 장점: 재해 복구에 강함 (Disaster Recovery), 운영 단순
    - ⚠️ 단점: Secondary 클러스터는 리소스 낭비처럼 느껴질 수 있음, Failover 절차 필요
```
           [Producer]
               |
               v
       ┌────────────────────┐
       │  Kafka Cluster A   │  ← Active (Primary)
       └────────────────────┘
               |
        MirrorMaker 2 / Cluster Linking
               |
               v
       ┌────────────────────┐
       │  Kafka Cluster B   │  ← Passive (DR/Backup)
       └────────────────────┘
```

 - `Geo-Partitioned Cluster`
    - 지역 기반으로 데이터 및 트래픽을 분산하고, 필요 시 일부 데이터만 공유하는 구조
    - 예: 아시아, 유럽, 미국에 각각 클러스터
    - 사용자 요청은 지역별 Kafka 클러스터로 전송
    - 글로벌 데이터만 복제 (예: 유저 프로필 변경사항 등)
    - 📌 장점: Latency 최소화, 데이터 주권 규제 대응에 유리 (예: GDPR)
    - ⚠️ 단점: 애플리케이션에서 지역 기반 라우팅 고려 필요, 일부 데이터는 여러 클러스터에 걸쳐 존재할 수 있음
```
               지역 A                                     지역 B
     ┌────────────────────┐                 ┌────────────────────┐
     │ Kafka Cluster A     │◄──Mirror──►│ Kafka Cluster B     │
     └────────────────────┘                 └────────────────────┘
             ▲       ▲                             ▲       ▲
         [ProdA] [ConsA]                   [ProdB] [ConsB]
```

 - `Service/Domain 기반 Cluster`
    - 조직의 서비스나 도메인(Bounded Context) 단위로 클러스터를 분리하는 구조
    - 예: "주문", "결제", "배송" 서비스별 Kafka 클러스터 운영
    - 연동은 Kafka → Kafka or Event → API 방식
    - 📌 장점: 장애 격리, 서비스 오너십 확실
    - ⚠️ 단점: 클러스터 간 데이터 이동 및 설계 필요, 운영 및 모니터링 복잡도 증가

## 3. Kafka EcoSystem

 - `메시지 브로커 및 클러스터 관리`
    - Kafka Broker: Kafka의 핵심 서버 역할. 토픽에 따라 메시지를 저장하고, 필요한 Consumer에게 전송합니다.
    - ZooKeeper (레거시): Kafka 클러스터의 메타데이터와 브로커 상태를 관리합니다. Kafka 2.8+부터는 KRaft로 대체 중입니다.
    - KRaft (Kafka Raft): Kafka 자체가 클러스터 메타데이터를 관리하는 내장 방식. ZooKeeper 없이 동작할 수 있도록 설계됨. Kafka 3.x부터 권장.
 - `데이터 수집 (Ingestion)`
    - Kafka Producer API: 애플리케이션이 Kafka에 데이터를 전송할 수 있도록 해주는 API. Java, Python, Go 등 다양한 언어 지원.
    - Kafka Connect (Source): DB, 로그 시스템, 파일 등 외부 데이터 소스를 Kafka로 자동 수집하는 프레임워크. 예: JDBC, Debezium.
    - Fluentd / Logstash: 로그 수집 에이전트. Kafka를 출력 대상으로 설정 가능. 주로 로그/이벤트 데이터 수집에 사용됨.
    - Filebeat / Metricbeat: 경량 로그 수집기 (Elastic Stack). Kafka와 통합하여 로그/메트릭 데이터를 전송 가능.
 - `데이터 처리 (Stream Processing)`
    - Kafka Streams: Kafka에서 데이터를 스트림 처리하고 변환하는 Java 기반의 라이브러리. 실시간 집계, 윈도잉 등에 적합.
    - ksqlDB: Kafka 스트림 데이터를 SQL 문법으로 처리하는 도구. Kafka Streams의 기능을 더 간편하게 사용 가능.
    - Apache Flink / Spark Streaming: Kafka에서 데이터를 읽어 복잡한 연산을 수행하는 빅데이터 처리 엔진. 정교한 실시간 분석에 활용.
 - `데이터 전송 (Export / Sink)`
    - Kafka Connect (Sink): Kafka 데이터를 외부 시스템으로 전송. 예: Elasticsearch, S3, PostgreSQL, BigQuery 등.
    - MirrorMaker: Kafka 클러스터 간 데이터 복제 도구. 멀티 리전, DR, 마이그레이션 등에 사용됨.
    - NiFi / Airbyte: Kafka 데이터를 다양한 시스템으로 라우팅/변환/전송하는 데이터 플로우 도구.
 - `스키마 및 데이터 형식 관리`
    - Schema Registry: Kafka 메시지의 스키마(Avro, Protobuf 등)를 중앙에서 관리. 데이터의 버전 관리와 호환성 체크 지원.
    - Avro / JSON / Protobuf: Kafka 메시지 포맷. Avro는 바이너리 형식으로 효율적이며, 스키마 기반이라 Schema Registry와 잘 연동됨.
 - `운영 및 모니터링`
    - Kafka Manager / CMAK: Kafka 브로커, 토픽, 파티션 등을 관리할 수 있는 웹 UI 도구.
    - Confluent Control Center: Confluent Kafka용 GUI 기반 모니터링 및 운영 툴. 커넥터 상태, 성능 등을 시각화.
    - Prometheus + Grafana: Kafka 메트릭 수집 및 시각화. JMX Exporter와 연계하여 Kafka 내부 상태 모니터링.
    - Burrow: Consumer 그룹의 lag(지연) 상태를 모니터링하는 도구. 안정성 확보에 유용함.
 - `인터페이스 및 API`
    - Kafka REST Proxy: Kafka 클러스터에 HTTP 기반 접근을 제공. 비 Kafka 클라이언트에서도 메시지 전송/조회 가능.
    - Kafka Admin API: 클러스터, 토픽, ACL 등을 프로그래밍 방식으로 관리할 수 있는 Kafka의 관리 API.


```
[클라이언트 / 외부 시스템]
    │
    ├── 애플리케이션 → Kafka Producer API
    ├── 로그 수집기 → Fluentd / Logstash / Filebeat
    └── DB, 시스템 → Kafka Connect (Source)
                     ↑
                     └── Debezium, JDBC 등 커넥터

            ▼

[Kafka 브로커 (Kafka Cluster)]
    ├── 메시지 저장 및 전달
    ├── 토픽 기반 파티셔닝
    ├── ZooKeeper or KRaft로 클러스터 메타데이터 관리

            ▼

[데이터 처리]
    ├── Kafka Streams (Java 기반 실시간 처리)
    ├── ksqlDB (SQL 기반 스트림 처리)
    └── Apache Flink / Spark Streaming (복잡한 처리)

            ▼

[외부 시스템 전송 (Sink)]
    ├── Kafka Connect (Sink)
    │     └── 예: Elasticsearch, S3, PostgreSQL 등
    └── MirrorMaker (다른 Kafka 클러스터로 복제)

            ▼

[Consumer 애플리케이션]
    ├── Kafka Consumer API 사용
    └── 실시간 서비스, 알림, 대시보드 등

            ▼

[운영 / 모니터링]
    ├── Prometheus + Grafana (메트릭 시각화)
    ├── Burrow (Consumer Lag 모니터링)
    ├── Kafka Manager / CMAK
    └── Confluent Control Center

            ▲
[스키마 및 데이터 형식 관리]
    ├── Schema Registry
    └── Avro / Protobuf / JSON
```
