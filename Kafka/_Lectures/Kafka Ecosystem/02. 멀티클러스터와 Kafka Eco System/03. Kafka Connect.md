# Kafka Connectì™€ MirrorMaker2

## 1. Kafka Connectì˜ í•„ìš”ì„±ê³¼ ì—­í• 

Kafka ConnectëŠ” Apache Kafkaì˜ êµ¬ì„± ìš”ì†Œ ì¤‘ í•˜ë‚˜ë¡œ, ì™¸ë¶€ ì‹œìŠ¤í…œ(ì˜ˆ: ë°ì´í„°ë² ì´ìŠ¤, íŒŒì¼ ì‹œìŠ¤í…œ, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ë“±)ê³¼ Kafka ê°„ì˜ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°ì„ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ëŠ” ë°ì´í„° í†µí•© í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

Kafka ConnectëŠ” Kafkaì™€ ë‹¤ë¥¸ ì‹œìŠ¤í…œ(ì˜ˆ: MySQL, PostgreSQL, Elasticsearch, S3 ë“±) ê°„ì— ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ê±°ë‚˜ ë‚´ë³´ë‚´ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì¦‰, ë°ì´í„°ë¥¼ Kafka í† í”½ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê±°ë‚˜, Kafkaì—ì„œ ë‹¤ë¥¸ ì‹œìŠ¤í…œìœ¼ë¡œ ë‚´ë³´ë‚´ëŠ” ê²ƒì„ ì½”ë“œ ì—†ì´ êµ¬ì„±ë§Œìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.

 - Source: Debezium (MySQL/Postgres CDC), JDBC Source, FileStream Source
 - Sink: Elasticsearch Sink, S3 Sink, JDBC Sink, Kafka to MongoDB Sink
 - Standalone Mode: í…ŒìŠ¤íŠ¸ë‚˜ ì†Œê·œëª¨ í”„ë¡œì íŠ¸ì— ì í•©. ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ë™ì‘.
 - Distributed Mode: í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©. ì—¬ëŸ¬ ì‘ì—…ì(worker)ê°€ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ë©° ìë™ ë¶„ì‚°, ì¥ì•  ë³µêµ¬ ì§€ì›.

<div align="center">
    <img src="./images/03.png">
</div>
<br/>

### 1-1. Kafka Connect êµ¬ì„± ìš”ì†Œ

 - `Connector (ì»¤ë„¥í„°)`
    - Kafka Connectì˜ ìµœìƒìœ„ êµ¬ì„± ìš”ì†Œ
    - Source ë˜ëŠ” Sink ì—­í• ì„ í•¨
    - ì‹¤ì œ ì‘ì—…ì„ ìˆ˜í–‰í•  Taskë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬
    - ì„¤ì • íŒŒì¼ ë˜ëŠ” REST APIë¥¼ í†µí•´ ì •ì˜ë¨
    - ì˜ˆ: MySQL Source Connector, Elasticsearch Sink Connector
 - `Task (íƒœìŠ¤í¬)`
    - Connectorê°€ ìƒì„±í•œ ì‘ì—… ë‹¨ìœ„
    - ë³‘ë ¬ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë©°, ì»¤ë„¥í„° ì„¤ì •ì—ì„œ ëª‡ ê°œì˜ íƒœìŠ¤í¬ë¡œ ë¶„í• í• ì§€ ì§€ì • ê°€ëŠ¥
    - ì‹¤ì œ ë°ì´í„° ì½ê¸°/ì“°ê¸° ë¡œì§ì„ ìˆ˜í–‰
    - ì˜ˆ: MySQL ì»¤ë„¥í„°ê°€ 3ê°œì˜ í…Œì´ë¸”ì„ ê°ê° 1ê°œì˜ Taskë¡œ ë¶„í• í•´ì„œ ë™ì‹œ ì²˜ë¦¬
 - `Worker (ì‘ì—…ì)`
    - Kafka Connect í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ ë‹¨ìœ„
    - Connectorì™€ Taskë¥¼ ì‹¤ì œë¡œ ì‹¤í–‰í•˜ëŠ” ì£¼ì²´
    - Standalone(ë‹¨ì¼ worker) ë˜ëŠ” Distributed(ë‹¤ìˆ˜ worker) ëª¨ë“œë¡œ ìš´ì˜ ê°€ëŠ¥
    - ê° workerëŠ” Kafka í† í”½ì— ì‘ì—… ìƒíƒœ, ì˜¤í”„ì…‹ ë“±ì„ ì €ì¥í•˜ê³  ê³µìœ í•¨
 - `Offset Storage (ì˜¤í”„ì…‹ ì €ì¥ì†Œ)`
    - Source Connectorê°€ ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ ì–´ë””ê¹Œì§€ ë°ì´í„°ë¥¼ ì½ì—ˆëŠ”ì§€ ì €ì¥
    - Kafka í† í”½ì— ì €ì¥ë¨ (connect-offsets, connect-status, connect-configs ë“±)
 - `Converter (ì»¨ë²„í„°)`
    - Kafka Connectê°€ ë°ì´í„°ë¥¼ Kafkaì— ì €ì¥í•  ë•Œ, ë˜ëŠ” ì™¸ë¶€ ì‹œìŠ¤í…œì— ë³´ë‚¼ ë•Œ ì§ë ¬í™”/ì—­ì§ë ¬í™”í•˜ëŠ” ì—­í• 
    - ê°€ì¥ í”í•œ í¬ë§·: JSONConverter, AvroConverter, ProtobufConverter
    - Schema Registryë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° Avro ë˜ëŠ” Protobufì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥
 - Transformation (Single Message Transform, SMT)
    - Kafka Connectê°€ ì²˜ë¦¬ ì¤‘ì¸ ê° ë©”ì‹œì§€ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥
    - ì˜ˆ: íŠ¹ì • í•„ë“œ ì œê±°, ì´ë¦„ ë³€ê²½, ë°ì´í„° ì •ê·œí™” ë“±
    - ì»¤ë„¥í„° ì„¤ì •ì— ê°„ë‹¨íˆ ì¶”ê°€í•˜ì—¬ ê°€ê³µ ê°€ëŠ¥

```
ğŸ”„ ì „ì²´ íë¦„ ì˜ˆì‹œ
1. Workerê°€ ì‹¤í–‰ë¨ â†’ Connector ë¡œë“œë¨
2. Connectorê°€ ì„¤ì •ì„ ì½ê³  Taskë¥¼ ë¶„í• 
3. ê° Taskê°€ ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ ë°ì´í„°ë¥¼ ì½ê±°ë‚˜ Kafkaë¡œ ë°ì´í„°ë¥¼ ì”€
4. ë°ì´í„°ëŠ” Converterë¥¼ í†µí•´ ì§ë ¬í™”ë˜ì–´ Kafka í† í”½ì— ì €ì¥
5. Offsetì€ Kafka ë‚´ë¶€ í† í”½ì— ì €ì¥ë˜ì–´ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì´ì–´ì„œ ì²˜ë¦¬
```

### 1-2. Source Connectorsì™€ Sink Connectors

<div align="center">
    <img src="./images/04.png"><br/>
    Kafkaë¡œ ë°ì´í„°ë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ì†ŒìŠ¤ ì»¤ë„¥í„°<br/>
    <img src="./images/05.png"><br/>
    Kafkaì˜ ì‹±í¬ ì»¤ë„¥í„° ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°<br/>
    https://docs.redhat.com/ko/documentation/red_hat_streams_for_apache_kafka/2.5/html/amq_streams_on_openshift_overview/kafka-connect-components_str#connectors
</div>
<br/>

 - `JDBC Source Connector (MySQL â†’ Kafka)`
    - connector.class: ì‚¬ìš©í•  ì»¤ë„¥í„° í´ë˜ìŠ¤ (JDBC Source)
    - mode: ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë°©ì‹ (incrementing: auto-increment ID ê¸°ì¤€)
    - topic.prefix: Kafkaì— ìƒì„±í•  í† í”½ ì´ë¦„ ì ‘ë‘ì‚¬ (mysql-users)
    - poll.interval.ms: ì£¼ê¸°ì ìœ¼ë¡œ DBì—ì„œ ë°ì´í„°ë¥¼ ì½ëŠ” ê°„ê²©
```json
{
  "name": "mysql-jdbc-source",
  "config": {
    "connector.class": "io.confluent.connect.jdbc.JdbcSourceConnector",
    "connection.url": "jdbc:mysql://localhost:3306/my_database",
    "connection.user": "root",
    "connection.password": "password",
    "table.whitelist": "users",
    "mode": "incrementing",
    "incrementing.column.name": "id",
    "topic.prefix": "mysql-",
    "poll.interval.ms": "10000"
  }
}
```

 - `Elasticsearch Sink Connector (Kafka â†’ Elasticsearch)`
    - topics: Kafkaì—ì„œ ì½ì„ í† í”½ ì´ë¦„
    - connection.url: Elasticsearch í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ
    - key.ignore: ë©”ì‹œì§€ í‚¤ ë¬´ì‹œ ì—¬ë¶€
    - schema.ignore: ìŠ¤í‚¤ë§ˆ ë¬´ì‹œ (Avro ë“±ì„ ì“°ì§€ ì•ŠëŠ” ê²½ìš° ìœ ìš©)
```json
{
  "name": "elasticsearch-sink",
  "config": {
    "connector.class": "io.confluent.connect.elasticsearch.ElasticsearchSinkConnector",
    "topics": "mysql-users",
    "connection.url": "http://localhost:9200",
    "type.name": "_doc",
    "key.ignore": "true",
    "schema.ignore": "true",
    "name": "elasticsearch-sink-connector"
  }
}
```

 - `ì ìš© ë°©ë²• (REST API)`
```bash
# íŒŒì¼ ë‚´ìš© ì „ë‹¬
curl -X POST -H "Content-Type: application/json" \
     --data @mysql-source.json \
     http://localhost:8083/connectors

# ì§ì ‘ ì „ë‹¬
curl -X POST -H "Content-Type: application/json" \
     --data '{
       "name": "mysql-jdbc-source",
       "config": {
         ...
       }
     }' \
     http://localhost:8083/connectors
```

## 2. Kafka Connect êµ¬ì„± ë° ì‹¤í–‰

<div align="center">
    <img src="./images/06.PNG">
</div>
<br/>

### 2-1. Kafka ì„œë²„ êµ¬ì„±

 - `zookeeper.service`
```bash
[Unit]
Requires=network.target remote-fs.target
After=network.target remote-fs.target

[Service]
Type=simple
User=ubuntu
ExecStart=/home/ubuntu/confluent-7.5.2/bin/zookeeper-service-start /home/ubuntu/confluent-7.5.2/etc/kafka/zookeeper.properties
ExecStop=/home/ubuntu/confluent-7.5.2/bin/zookeeper-service-stop
Restart=on-abnormal

[Install]
WantedBy=multi-user.target
```

 - `kafka.service`
```bash
[Unit]
Requires=zookeeper.service
After=zookeeper.service

[Service]
Type=simple
User=ubuntu
ExecStart=/bin/sh -c '/home/ubuntu/confluent-7.5.2/bin/kafka-server-start /home/ubuntu/confluent-7.5.2/etc/kafka/server.properties > /home/ubuntu/kafka/kafka.loog 2>&1'
ExecStop=/home/ubuntu/confluent-7.5.2/bin/kafka-server-stop
Restart=on-abnormal

[Install]
WantedBy=multi-user.target
```

```bash
# zookeeper.service, kafka.service ë“±ë¡ ë° í™œì„±í™”
sudo systemctl daemon-reload
sudo systemctl enable zookeeper.service
sudo systemctl enable kafka.service
sudo systemctl start zookeeper.service
sudo systemctl start kafka.service

# ë™ì‘ í™•ì¸
service kafka status
ps -ef|grep kafka
```

### 2-2. Connect ì„œë²„ êµ¬ì„±

 - Kafka Connectë¥¼ systemd ì„œë¹„ìŠ¤ë¡œ ë“±ë¡í•´ì„œ ì‹œìŠ¤í…œ ë¶€íŒ… ì‹œ ìë™ ì‹œì‘ ê°€ëŠ¥
 - systemctl start|stop|restartë¡œ ì œì–´ ê°€ëŠ¥
 - ë¹„ì •ìƒ ì¢…ë£Œ ì‹œ ìë™ ì¬ì‹œì‘ ê°€ëŠ¥
```bash
cd /home/ubuntu/confluent-7.5.2/etc/kafka
vi connect-distributed.properties

bootstrap.servers={Kafka-Server-Private-IP}:9092

# systemd ì„œë¹„ìŠ¤ ìœ ë‹› ìƒì„±
cd /etc/systemd/sysmte
vi connect.service
[Unit]
Description=My Connect Service
After=network.target

[Service]
Type=simple
User=ubuntu
ExecStart=/home/ubuntu/confluent-7.5.2/bin/connect-distributed /home/ubuntu/confluent-7.5.2/etc/kafka/connect-distributed.properties
Restart=on-abnormal

[Install]
WantedBy=multi-user.target

# connect.service ë“±ë¡ ë° í™œì„±í™”
sudo systemctl daemon-reload
sudo systemctl enable connect.service
sudo service connect stat

# í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜
apt-get update
wget https://repo1.maven.org/maven2/io/debezium/debezium-connector-postgres/2.3.5.Final/debezium-connector-postgres-2.3.5.Final-plugin.tar.gz
tar â€“xvf debezium-connector-postgres-2.3.5.Final-plugin.tar.gz
```

### 2-3. PostgreSQL ì„œë²„ êµ¬ì„±

```bash
# postgresql ì„¤ì¹˜
sudo apt-get update
sudo apt install postgresql-14

# postgresql ì ‘ê·¼ ì„¤ì •
cd /etc/postgresql/14/main
vi pg_hba.conf
local all postgres trust (peerë¥¼ ë³€ê²½)
local all all password (perrë¥¼ ë³€ê²½)

vi postgresql.conf
wal_level = logical

# popostgresql ì¬ì‹¤í–‰
service postgresql restart

# postgresql ì ‘ê·¼
psql -U postgres -d postgres

# ê³„ì • ìƒì„±
CREATE USER fastadnm WITH PASSWORD 'fastadm' SUPERUSER;
```

### 2-4. Kafka UI ì„œë²„ êµ¬ì„±

```bash
sudo apt-get update
sudo wget -qO- http://get.docker.com/ | sh. 
docker run -d -p 8080:8080 -e DYNAMIC_CONFIG_ENABLED=true provectuslabs/kafka-ui
```


## 3. Kafka Source Connector ì‹¤ìŠµ

### 3-1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (Postgre)

```sql
create table fast_jdbc_test (
	row_id			varchar(144) PRIMARY KEY NOT NULL,
	contents			varchar(144),
	created_dt 		timestamp
);

insert into fast_jdbc_test 
values ('1', 'connect test', NOW());
insert into fast_jdbc_test 
values ('2', 'connect test 2', NOW());
insert into fast_jdbc_test 
values ('3', 'connect test 3', CAST(now() AS DATE));
insert into fast_jdbc_test 
values ('4', 'CT4', NOW());
insert into fast_jdbc_test 
values ('5', 'CT5', NOW());
insert into fast_jdbc_test 
values ('6', 'CT6', NOW());
insert into fast_jdbc_test 
values ('7', 'CT7', NOW());
insert into fast_jdbc_test 
values ('8', 'CT8', NOW());
insert into fast_jdbc_test 
values ('9', 'CT9', NOW());
insert into fast_jdbc_test 
values ('10', 'CT10', NOW());
insert into fast_jdbc_test 
values ('11', 'CT11', NOW());
insert into fast_jdbc_test 
values ('12', 'CT12', NOW());
insert into fast_jdbc_test 
values ('13', 'CT13', NOW());
```

### 3-2. Source Connector

 - `my-avro-src-connector.json`
```json
{
  "name":"debe-avro-postgres-source-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "tasks.max": "1",
    "database.hostname": "IP ì£¼ì†Œ",
    "database.port": "5432",
    "database.user": "fastadm",
    "database.password": "fastadm",
    "database.dbname": "srcDB",
    "database.server.name": "fastdb",
    "table.whitelist": "fast_jdbc_test",
    "topic.prefix": "debeavro-source-",
    "transforms": "unwrap",
    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
    "transforms.unwrap.drop.tombstones": "false",
    "transforms.unwrap.delete.handling.mode": "rewrite"
  }
}
```

 - `my-avro-src-connector.json`
```json
{
  "name":"debe-json-postgres-source-connector",
  "config": {
    "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
    "tasks.max": "1",
    "database.hostname": "IP ì£¼ì†Œ",
    "database.port": "5432",
    "database.user": "fastadm",
    "database.password": "fastadm",
    "database.dbname": "srcDB",
    "database.server.name": "fastdb",
    "table.whitelist": "fast_jdbc_test",
    "topic.prefix": "debe-json-source-",
    "transforms": "unwrap",
    "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
    "transforms.unwrap.drop.tombstones": "false",
    "transforms.unwrap.delete.handling.mode": "rewrite",
    "key.converter": "org.apache.kafka.connect.json.JsonConverter",
    "key.converter.schemas.enable": "false",
    "value.converter": "org.apache.kafka.connect.json.JsonConverter",
    "value.converter.schemas.enable": "false"
  }
}
```

 - `Source Connector ë“±ë¡`
```bash
# ë“±ë¡
curl -X POST -H "Content-Type: application/json" --data @my-avro-src-connector.json http://localhost:8083/connectors

# ìƒíƒœ í™•ì¸
curl -X GET http://localhost:8083/connectors/debe-json-postgre-source-connector/status
```


## 4. Kafka Sink Connector ì‹¤ìŠµ

 - `Sink ê´€ë ¨ Plugin ë‹¤ìš´ë¡œë“œ`
```bash
wget -O https://repo1.maven.org/maven2/io/debezium/debezium-connector-jdbc/2.5.0.Final/debezium-connector-jdbc-2.5.0.Final-plugin.tar.gz

tar -xvf debezium-connector-jdbc-2.5.0.Final-plugin.tar.gz
```

```bash
cd /usr/share/java

vi debe-avro-postgre-sink-connector.json 
{
    "name": "kafka-to-rdb",
    "config": {
        "connector.class": "io.debezium.connector.jdbc.JdbcSinkConnector",
        "tasks.max": "1",
        "connection.url": "jdbc:postgresql://{ip}/tgtDB",
        "connection.username": "fastadm",
        "connection.password": "fastadm",
        "insert.mode": "upsert",
        "delete.enabled": "true",
        "primary.key.mode": "record_key",
        "schema.evolution": "basic",
        "database.time_zone": "UTC",
        "topics": "debe-avro-source-.public.test_jdbc_test",
        "transforms": "unwrap",
        "transforms.unwrap.type": "io.debezium.transforms.ExtractrNewRecordState",
        "transforms.unwrap.drop.tombstones": "false",
        "transforms.unwrap.delete.handling.mode": "none"
    }
}

curl -X POST -H "Content-Type: application/json" --data @debe-avro-postgre-sink-connector.json 
http://localhost:8083/connectors
```
