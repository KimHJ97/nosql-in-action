# Schema Registry

## 1. 스키마 관리의 필요성

Apache Kafka에서의 스키마(Schema) 는 메시지 또는 데이터의 구조 정의하는 객체의 정보입니다.

 - subject: 해당 schema의 이름입니다.
 - field: table의 column과 같습니다.
 - datatype: 각 field가 가지게 되는 데이터의 형식을 정의합니다.
 - default value: 값이 입력되지 않았을 때 갖게되는 정보의 value입니다.
 - constraints: 특정 범위나 제약을 가질 수 있습니다.
 - metadata: version, desc 등 기본적 정보입니다
 - namespace: schema가 저장될 공간을 의미합니다. 파일이 담기는 폴더라고 보시면 됩니다.
 - compatibility: 스키마가 가질 수 있는 정책유무와 방식이 담겨있습니다.

## 2. Schema Registry

Confluent Schema Registry는 Kafka 메시지의 스키마를 중앙에서 등록/조회/버전 관리해주는 시스템입니다.

 - 생산자: 메시지를 보낼 때 해당 스키마를 Registry에 등록하거나 확인
 - 소비자: 메시지를 받을 때 Registry에서 스키마를 받아서 해석
 - Kafka 메시지에는 보통 스키마 ID만 포함되고, 본문은 바이너리로 인코딩되어 있다.
 - __Storing__: 스키마 레지스트리는 Avro, JSON Schema, 또는 Protobuf와 같은 포맷으로 정의된 스키마를 저장하고 관리합니다.
 - __Versioning__: 각 스키마에 대해 여러 버전을 관리할 수 있으며, 스키마의 진화 과정을 추적할 수 있습니다.
 - __Control__: 스키마 레지스트리는 스키마 변경 사항이 기존 스키마와 호환되는지 여부를 검사합니다. 이는 데이터의 일관성과
무결성을 유지하는 데 중요합니다.

### 2-1. Avro Schema 예시


 - 정의된 스키마를 Schema Registry에 등록하고,
 - Kafka Producer는 이 구조에 맞게 데이터를 전송
 - Consumer는 Registry에서 스키마를 참조해 데이터를 해석
```json
{
  "type": "record",
  "name": "User",
  "fields": [
    { "name": "id", "type": "string" },
    { "name": "age", "type": "int" },
    { "name": "email", "type": ["null", "string"], "default": null }
  ]
}
```

### 2-2. Schema Evolution (스키마 진화)

스키마는 시간이 지나면서 변경될 수 있다. 호환성 정책을 고려해서 변화에 유연해야 한다.

Kafka 메시지는 바이트 배열이기 때문에, 생산자(Producer)가 보낸 스키마와 소비자(Consumer)가 기대하는 스키마가 다르면 문제가 생길 수 있다.

Schema Registry는 스키마 버전 간의 호환 여부를 자동 검증해준다.

 - `BACKWARD`
    - 새 스키마로 과거 데이터를 읽을 수 있어야 함
    - 소비자는 이전 버전 유지
    - 이전 버전의 컨슈머가 새로운 스키마로 생성된 데이터를 문제없이 처리할 수 있다.
```json
// 기존 스키마
{
  "type": "record",
  "name": "User",
  "fields": [
    { "name": "id", "type": "string" }
  ]
}

// 신규 스키마
// Consumer가 이전 스키마(id만 있음) 기준으로 데이터를 읽을 수 있으므로 BACKWARD 호환 OK
{
  "type": "record",
  "name": "User",
  "fields": [
    { "name": "id", "type": "string" },
    { "name": "email", "type": ["null", "string"], "default": null }
  ]
}
```

 - `FORWARD`
    - 이전 스키마로 새 데이터를 읽을 수 있어야 함
    - 소비자가 먼저 업데이트됨
    - 이전 버전의 프로듀서가 생성한 데이터는 새로운 버전의 컨슈머도 처리할 수 있다.
 - `FULL`
    - 양방향 모두 호환 (Backward + Forward)
    - 안정성 최우선일 때
    - 프로듀서는 새로운 필드를 추가하거나 기존 필드를 수정할 때, 이전 버전의 컨슈머와 미래 버전의 컨슈머 모두  호환될 수 있도록 한다. 이를 위해 새로운 필드는 옵셔널로 추가하고, 중요한 필드는 제거하지 않는다.
 - `NONE`
    - 호환성 체크 안 함
    - 버전마다 전혀 다르게 해도 됨
    - 실험적이거나 자유롭게 쓸 때

### 2-3. 정책 적용 예시

```bash
# 스키마 등록 (POST)
curl -X POST http://localhost:8081/subjects/my-topic-value/versions \
  -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  -d '{
    "schema": "{\"type\":\"record\",\"name\":\"User\",\"fields\":[{\"name\":\"id\",\"type\":\"string\"},{\"name\":\"email\",\"type\":[\"null\", \"string\"],\"default\":null}]}"
  }'

# 호환성 정책 설정 (PUT)
# BACKWARD 호환성으로 설정
# 전역 설정이 아니라 특정 subject에만 적용
curl -X PUT http://localhost:8081/config/my-topic-value \
  -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  -d '{"compatibility": "BACKWARD"}'

# 현재 호환성 정책 확인 (GET)
curl -X GET http://localhost:8081/config/my-topic-value

# 전역 호환성 정책 설정
curl -X PUT http://localhost:8081/config \
  -H "Content-Type: application/vnd.schemaregistry.v1+json" \
  -d '{"compatibility": "FULL"}'
```

## 3. Schema Registry 실습

```bash
# 1. 부트스트랩 서버 변경
vi /home/ubuntu/confluent-7.5.2/etc/schema-registry/schema-registry.properties
kafkastore.bootstrap.servers=PLAINTEXT://kafkahost:9092 

# 2. 스키마 레지스트리 실행
/home/ubuntu/confluent-7.5.2/bin/schema-registry-start /home/ubuntu/confluent-7.5.2/etc/schema-registry/schemaregistry.properties &

# 3. Kafka-ui configure 에서 schema registry 설정

# 4. Schema 생성
curl -X POST -H "Content-Type: application/vnd.schemaregistry.v1+json" \
--data '{"schema": "{\"type\":\"record\",\"name\":\"ProductInfoV1\",\"fields\":[{\"name\":\"product_id\",\"type\":\"string\"},{\"name\":\"price\",\"type\":\"double\"}]}"}' \
http://IP:8081/subjects/prod_info/versions

# 5. Kakfa-ui 에서 생성 (Cluster – Schema Registry – Create Schema)
subject: prod_info
{
    "type": "record",
    "name": "ProductInfoV1",
    "fields": [
        {"name": "product_id", "type": "string"},
        {"name": "price", "type": "double"}
    ]
}

# Producer에서 메시지 발행: 정상
echo '{"product_id": "P001", "price": 38.99}' | ./kafka-avro-console-producer \
    --broker-list localhost:9092 \
    --topic pp1 \
    --property schema.registry.url=http://IP:8081 \
    --property value.schema.id=8

# Producer에서 메시지 발행: 실패 (seeler_id가 없음)
echo '{"product_id": "P003", "seller_id": "S002"}' | ./kafka-avro-console-producer \
    --broker-list localhost:9092 \
    --topic pp1 \
    --property schema.registry.url=http://IP:8081 \
    --property value.schema.id=8

# 호환성이 없는 신규 Schema 등록: 실패 (price가 없어서 이전 스키마 호환이 안됨)
{
    "type": "record",
    "name": " ProductInfoV1",
    "fields": [
        {"name": "product_id", "type": "string"},
        {"name": "seller_id", "type": "string"}
    ]
}

# 호환성이 있는 신규 Schema 등록
{
    "type": "record",
    "name": " ProductInfoV1",
    "fields": [
        {"name": "product_id", "type": "string"},
        {"name": "price", "type": "double"},
        {"name": "seller_id", "type": "string", "default": "none"}
    ]
}
```
