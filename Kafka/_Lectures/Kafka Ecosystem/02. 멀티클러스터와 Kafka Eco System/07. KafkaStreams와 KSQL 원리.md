# KafkaStreams와 KSQL 원리

## 1. Kafka 동작과 KafkaStreams 원리 (질문사항 요약)

 - Kafka는 __토픽에 메시지를 한 건씩 발행__ 하고, 컨슈머도 __한 건씩 읽는다.__
 - 그런데 Kafka Streams나 KSQL을 보면 __리스트처럼 일괄 처리__ 하거나, KSQL은 __테이블처럼 보관된 걸 쿼리__ 하는 것처럼 보인다.
 - __이게 어떻게 가능할까?__
 - 내부에서 Kafka는 어떤 식으로 동작할까?

## 2. 기본 개념 다시 정리: Kafka의 핵심은 "Append-only log"

"계속 이어지는 로그파일" 처럼 한 줄씩 쌓고, 한 줄씩 읽는다.

 - Kafka는 기본적으로 메시지를 __순차적으로 저장하는 로그 시스템__ 이다.
 - __프로듀서__ 가 메시지를 발행하면, Kafka는 이를 토픽의 __파티션에 차례대로 추가__ 한다.
 - 컨슈머는 파티션을 하나씩 읽으며 __자신의 offset을 이동__ 시켜가며 처리한다.

## 3. Kafka Streams / ksqlDB 내부 동작

### 3-1. Kafka Streams: 메시지를 한 건씩 읽으면서도 상태(state)를 유지한다

Kafka Streams는 사실 __Kafka에서 오는 메시지를 하나씩 읽는다.__ 하지만, 그걸 기억(= 상태 저장소 사용)해서 집계하거나 조인하거나 윈도우 처리를 가능하게 만든다.

 - 메시지가 한 건씩 들어온다. {"userId": "user1"} -> {"userId": "user2"} -> {"userId": "user1"}
 - Kafka Streams는 메시지를 처리하면서, 로컬 상태 저장소(RocksDB)에 "user1은 지금까지 2건" 이라고 저장한다.
 - 새로운 메시지가 들어올 때마다 상태를 업데이트하고,
필요할 때 새로 계산된 값을 출력 토픽에 보낸다.
```java
stream.groupByKey().count().toStream().to("output");
```

Kafka Streams는 하나씩 읽지만, 그 결과를 마치 리스트처럼 / 테이블처럼 유지한다.

### 3-2. KSQL (ksqlDB): 내부적으로 Kafka Streams 위에서 SQL처럼 조작

실시간으로 Kafka에서 한 건씩 들어오는 메시지를 계속 필터링해서 출력하는 구조이다. 기존에 쌓인 데이터를 한꺼번에 SELECT 하는 DB처럼 보일 수 있지만, 실은 스트리밍이다.

 - CREATE STREAM 이라는 명령은 실제로는 Kafka Streams 애플리케이션을 생성한다.
 - 그 애플리케이션은 Kafka에서 하나씩 데이터를 읽고, 조건에 맞는 것만 새 토픽으로 보낸다.
 - 우리가 보는 "테이블처럼 보이는 뷰"는, 사실은 계속 갱신되는 최신 상태이다.

```sql
SELECT * FROM clicks WHERE page = 'home';
```

## 4. Kafka Streams와 KSQL이 상태를 유지하는 원리

### 4-1. Kafka Streams 상태 유지 방식

Kafka Streams는 RocksDB라는 로컬 키-값 저장소를 이용해서 상태(예: 카운트, 조인 대상 등)를 저장한다.

이 상태는 장애 복구를 위해 Kafka의 체인지 로그 토픽에도 복제된다.

### 4-2. KSQL의 테이블 (KTable)

 - 아래 쿼리는 실제로 KafkaStreams로 동작한다.
    - 클릭이 발생할 때마다 Kafka에서 한 건씩 읽는다.
    - userId 기준으로 그룹핑
    - 상태 저장소에 누적 count 저장 (user1 → 3, user2 → 7)
    - 새로운 count가 계산될 때마다 Kafka 토픽에 최신 값을 발행
```sql
CREATE TABLE user_clicks AS
SELECT userId, COUNT(*) FROM clicks GROUP BY userId;
```
