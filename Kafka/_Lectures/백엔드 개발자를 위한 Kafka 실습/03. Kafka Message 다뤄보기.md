# Kafka Message 다뤄보기

## 1. 배치리스너(Batch Listener)

Kafka에서 배치(Batch) 리스너를 사용하면 한 번에 여러 개의 메시지를 가져와서 처리할 수 있습니다.

이를 통해 성능을 최적화하고 메시지 처리 속도를 향상시킬 수 있습니다.

 - 기본 @KafkaListener는 한 번에 하나의 메시지를 소비하지만, 배치 리스너는 한 번에 여러 개의 메시지를 List 형태로 소비할 수 있습니다.
 - 성능 향상: 여러 개의 메시지를 한 번에 가져와 처리하므로 I/O 성능이 개선됨.
 - 오프셋 관리 용이: 한 번에 여러 개의 메시지를 가져온 후, 오프셋을 한 번만 커밋 가능.
 - CPU 부하 감소: 개별 메시지 처리보다 더 효율적.

### 1-1. 예시 코드

 - `ThirdKafkaConfig`
```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.autoconfigure.kafka.KafkaProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class ThirdKafkaConfig {

    @Bean
    @Qualifier("batchConsumerFactory")
    public ConsumerFactory<String, MyMessage> batchConsumerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");
        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, "false");
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, ConsumerConfig.DEFAULT_MAX_POLL_RECORDS);
        return new DefaultKafkaConsumerFactory<>(
            props,
            new StringDeserializer(),
            new JsonDeserializer<>(MyMessage.class)
        );
    }

    @Bean
    @Qualifier("batchKafkaListenerContainerFactory")
    public ConcurrentKafkaListenerContainerFactory<String, MyMessage> batchKafkaListenerContainerFactory(
        @Qualifier("batchConsumerFactory") ConsumerFactory<String, MyMessage> batchConsumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, MyMessage> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(batchConsumerFactory);
        factory.setConcurrency(1);

        // 배치 리스너 활성화
        factory.setBatchListener(true);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.BATCH);

        return factory;
    }
}
```

 - `Consumer`
```java
@Component
public class MyThirdConsumer {

    @KafkaListener(
        topics = { MY_JSON_TOPIC },
        groupId = "batch-test-consumer-group", // MyConsumer의 groupId와 반드시 달라야 함!
        containerFactory = "batchKafkaListenerContainerFactory"
    )
    public void accept(List<ConsumerRecord<String, MyMessage>> messages) {
        System.out.println("[Third Consumer] Batch message arrived! - count " + messages.size());
        messages.forEach(message -> {
                System.out.println("ㄴ [Third Consumer] Value - " + message.value() + " / Offset - " + message.offset() + " / Partition - " + message.partition());
            }
        );
    }
}
```

## 2. String 형태로 받아서 Serialize/Deserialize

 - `application.yml`
```yml
spring:
  kafka:
    bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      acks: 1
```

 - `KafkaCofnig`
```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.autoconfigure.kafka.KafkaProperties;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;
import org.springframework.kafka.listener.ContainerProperties;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class KafkaConfig {

    @Bean
    @Primary
    @ConfigurationProperties("spring.kafka")
    public KafkaProperties kafkaProperties() {
        return new KafkaProperties();
    }

    @Bean
    @Primary
    public ConsumerFactory<String, Object> consumerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, kafkaProperties.getConsumer().getKeyDeserializer());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, kafkaProperties.getConsumer().getValueDeserializer());
        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, "false");
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        factory.setConcurrency(1);

        return factory;
    }

    @Bean
    @Qualifier("batchConsumerFactory")
    public ConsumerFactory<String, Object> batchConsumerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, kafkaProperties.getConsumer().getKeyDeserializer());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, kafkaProperties.getConsumer().getValueDeserializer());
        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, "false");
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, ConsumerConfig.DEFAULT_MAX_POLL_RECORDS);
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    @Qualifier("batchKafkaListenerContainerFactory")
    public ConcurrentKafkaListenerContainerFactory<String, Object> batchKafkaListenerContainerFactory(
            @Qualifier("batchConsumerFactory") ConsumerFactory<String, Object> batchConsumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(batchConsumerFactory);
        factory.setBatchListener(true);
        factory.setConcurrency(1);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.BATCH);
        return factory;
    }

    @Bean
    @Primary
    public ProducerFactory<String, Object> producerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, kafkaProperties.getProducer().getKeySerializer());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, kafkaProperties.getProducer().getValueSerializer());
        props.put(ProducerConfig.ACKS_CONFIG, kafkaProperties.getProducer().getAcks());
        return new DefaultKafkaProducerFactory<>(props);
    }

    @Bean
    @Primary
    public KafkaTemplate<String, ?> kafkaTemplate(KafkaProperties kafkaProperties) {
        return new KafkaTemplate<>(producerFactory(kafkaProperties));
    }
}
```


 - `Producer`
    - DTO 객체를 ObjectMapper로 JSON 문자열로 변환
    - JSON 문자열을 Kafka 형식 바이트 데이터로 Serialize하여 메시지 발행
```java
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@RequiredArgsConstructor
@Component
public class MyProducer {

    private final ObjectMapper objectMapper;
    private final KafkaTemplate<String, String> kafkaTemplate;

    public void sendMessage(MyMessage message) throws JsonProcessingException {
        kafkaTemplate.send(
            Topic.MY_JSON_TOPIC,
            String.valueOf(message.getAge()),
            objectMapper.writeValueAsString(message)
        );
    }
}
```

 - `Consumer`
    - Kafka의 메시지를 가져와서 Java의 String 형식으로 Deserialize
    - String 형식의 값(JSON 문자열)을 ObjectMapper로 DTO로 변환
```java
import com.fasterxml.jackson.databind.ObjectMapper;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Component;

@Component
public class MyConsumer {

    private final ObjectMapper objectMapper = new ObjectMapper();

    @KafkaListener(
        topics = { MY_JSON_TOPIC },
        groupId = "test-consumer-group"
    )
    public void listen(ConsumerRecord<String, String> message, Acknowledgment acknowledgment) throws JsonProcessingException {
        MyMessage myMessage = objectMapper.readValue(message.value(), MyMessage.class);
        System.out.println("[Main Consumer] Message arrived! - " + myMessage);
        acknowledgment.acknowledge();
    }
}
```

## 3. 자동커밋과 수동커밋

 - 자동 커밋
    - auto.commit.interval.ms 값에 따라 자동 커밋
    - 기본값은 5초
 - 수동 커밋(Manual Commit)
```java
// KafkaConfig
@Configuration
@EnableKafka
public class KafkaConfig {

    // ..

    @Bean
    @Primary
    public ConsumerFactory<String, Object> consumerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        // ..

        // 자동 커밋 비활성화
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, "false");
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);

        // AckMode를 MANUAL로 변경(수동 커밋)
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        factory.setConcurrency(1);

        return factory;
    }
}

// Consumer
// acknowledge() 메서드로 직접 커밋
@Component
public class MyConsumer {

    private final ObjectMapper objectMapper = new ObjectMapper();

    @KafkaListener(
        topics = { MY_JSON_TOPIC },
        groupId = "test-consumer-group"
    )
    public void listen(ConsumerRecord<String, String> message, Acknowledgment acknowledgment) throws JsonProcessingException {
        MyMessage myMessage = objectMapper.readValue(message.value(), MyMessage.class);
        System.out.println("[Main Consumer] Message arrived! - " + myMessage);
        acknowledgment.acknowledge();
    }
}
```

## 4. 중복 컨슘이 일어날 수 있는 Case

 - __컨슘이 중복되거나 누락되는 경우__
    - 컨슈머가 카프카 브로커로부터 메시지를 가져와서 데이터를 처리할 텐데, 만일 중복 컨슘이 발생하면 그 데이터 처리도 중복으로 이루어질 수 있다.
    - 떄로는 컨슘 누락이 발생할 수도 있다. 그럼 데이터 처리도 누락된다.
 - __이 문제를 막기 어려운 이유__
    - 커밋 시점과 데이터 처리 완료 시점이 완벽하게 일치할 수 없다. (시간 간극 동안 리밸런싱이 일어날 수도 있다.)
    - 오프셋 관리가 컨슈머측이 아니라 브로커 측에서 이루어진다.
    - 개발자 자의에 의해 offset reset을 해서 다시 컨슘할 일이 종종 있다.
 - __자동 커밋 - 누락 발생 사례__
    - Fetch로 데이터 조회 후 애플리케이션에서 데이터를 처리하고, 자동 커밋 주기가 되었다. 이때, 1번과 2번은 데이터 처리가 되었지만 읽어온 3번은 처리가 되지 않았을 때 커밋이 발생한다. 여기서 Rebalence가 일어나면 컨슈머와 파티션과의 관계가 끊어지고 새로운 관계가 일어난다. Broker 측의 기준으로 메시지 컨슘이 재개된다. 즉 4번부터 Fetch가 일어난다. 3번 메시지는 누실된다.
 - __자동 커밋, 수동 커밋 - 중복 발생 사례__
    - Fetch로 데이터 조회 후 애플리케이션에서 데이터를 처리하고, 커밋을 하기 전에 Rebalence가 일어나면 데이터 중복이 발생한다.
    - 1, 2번 데이터를 Fetch 후 데이터 처리하고, 커밋 전에 Rebalence가 일어나면 다시 Fetch할 때 1, 2번 데이터를 읽게 된다.
 - __리밸런싱이 문제다.__
    - 리밸런싱이 자주 일어나면 여러가지가 문제가 될 수 있다.
    - 리밸런싱이 일어나면서, 중복 컨슘 혹은 컨슘 누락 가능성이 발생하는 타이밍이 생긴다.
    - 심지어, 리밸런싱이 일어나는 동안 컨슘이 멈추기 때문에 성능상 문제도 있다.
 - __리밸런싱 발생 시점__
    - 파티션이 추가되거나 리어사인 된 경우(브로커 측의 변화)
    - 컨슈머 그룹 내 컨슈머가 추가되거나 제거된 경우(컨슈머 측의 변화)
        - session.timeout.ms와 heatbeat.interval.ms
            - heartbeat가 한 동안 오지 않아 timeout 되면, 컨슈머 상태 비정상으로 판단
        - max.poll.interval.ms
            - poll을 한 동안 하지 않으면, 컨슈머 상태 비정상으로 판단
 - __정리__
    - 중복 컨슘 및 컨슘 누락은 컨슈머만의 입장이다. commit 관점에서는 단 한번만 레코드를 다루는 것이 맞다.
    - 대비하면, 리밸런싱을 줄일 수 있게 옵션값을 잘 설정한다. 일반적으로 중복이 누락보다는 낫다. 실무에서는 수동 커밋을 활용한다.

## 5. Exactly Once Semantics (EOS)

Kafka에서 EOS (Exactly Once Semantics, 정확히 한 번 처리) 는 메시지를 중복 없이 한 번만 처리하도록 보장하는 기능입니다. Kafka의 기본적인 메시징 모델에서는 최소 한 번(at-least-once) 또는 최대 한 번(at-most-once) 보장을 제공하지만, EOS를 활용하면 데이터가 중복되지 않으면서도 한 번만 안전하게 처리될 수 있습니다.

 - Idempotent Producer (멱등한 프로듀서)
    - Kafka의 Producer가 동일한 메시지를 여러 번 전송하더라도 한 번만 처리되도록 보장하는 기능입니다.
    - Kafka 0.11부터 enable.idempotence=true 옵션을 사용하면 활성화됩니다.
    - Producer가 동일한 메시지를 다시 보낼 경우, Kafka가 중복을 감지하고 하나의 메시지만 저장하도록 합니다.

```java
@Bean
public ProducerFactory<String, String> producerFactory() {
    Map<String, Object> configProps = new HashMap<>();
    configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
    configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
    
    // Exactly-Once를 위한 설정
    configProps.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);  // 멱등성 활성화
    configProps.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, "my-transactional-id");  // 트랜잭션 ID 설정

    DefaultKafkaProducerFactory<String, String> factory = new DefaultKafkaProducerFactory<>(configProps);
    factory.setTransactionIdPrefix("txn-"); // 트랜잭션을 위한 Prefix 설정
    return factory;
}
```

## 6. 멱등성 보장

```java
@Component
public class MyConsumer {

    private final ObjectMapper objectMapper = new ObjectMapper();
    private final Map<String, Integer> idHistoryMap = new ConcurrentHashMap<>(); // id에 대해 Exactly Once를 보장하기 위함

    @KafkaListener(
        topics = { MY_JSON_TOPIC },
        groupId = "test-consumer-group"
    )
    public void listen(ConsumerRecord<String, String> message, Acknowledgment acknowledgment) throws JsonProcessingException {
        MyMessage myMessage = objectMapper.readValue(message.value(), MyMessage.class);
        this.printPayloadIfFirstMessage(myMessage);
        acknowledgment.acknowledge();
    }

    private synchronized void printPayloadIfFirstMessage(MyMessage myMessage) {
        if (idHistoryMap.get(String.valueOf(myMessage.getId())) == null) {
            System.out.println("[Main Consumer] Message arrived! - " + myMessage); // Exactly Once 실행되어야 하는 로직으로 가정
            idHistoryMap.put(String.valueOf(myMessage.getId()), 1);
        } else {
            System.out.println("[Main Consumer] Duplicate! (" + myMessage.getId() + ")");
        }
    }

    private void printPayloadIfFirstMessage2(MyMessage myMessage) {
        if (idHistoryMap.putIfAbsent(String.valueOf(myMessage.getId()), 1) == null) {
            System.out.println("[Main Consumer] Message arrived! - " + myMessage); // Exactly Once 실행되어야 하는 로직으로 가정
        } else {
            System.out.println("[Main Consumer] Duplicate! (" + myMessage.getId() + ")");
        }
    }
}
```

## 7. 처리량(Throughput) 개선

파티션과 컨슈머의 개수가 같으면, 처리량을 개선할 수 있다.

컨슈머가 파티션보다 많으면 남은 컨슈머는 유휴상태가 된다. 각 파티션별로 하나의 컨슈머만 데이터를 가져가도록 하여 순서 보장을 하기 위해서 설계되었다.

```java
@Component
public class MyBatchConsumer {

    private final ObjectMapper objectMapper = new ObjectMapper();

    @KafkaListener(
        topics = { MY_JSON_TOPIC },
        groupId = "batch-test-consumer-group",
        containerFactory = "batchKafkaListenerContainerFactory",
        concurrency = "3" 
    )
    public void listen(List<ConsumerRecord<String, String>> messages) {
        System.out.println("[Batch Consumer] Batch message arrived! - count " + messages.size());
        messages.forEach(message -> {
            MyMessage myMessage;
            try {
                myMessage = objectMapper.readValue(message.value(), MyMessage.class);
            } catch (JsonProcessingException e) {
                throw new RuntimeException(e);
            }
            System.out.println("ㄴ [Batch Consumer(" + Thread.currentThread().getId() + ")] " + "[Partition - " + message.partition() + " / Offset - " + message.offset() + "] " + myMessage);
        });
    }
}
```
