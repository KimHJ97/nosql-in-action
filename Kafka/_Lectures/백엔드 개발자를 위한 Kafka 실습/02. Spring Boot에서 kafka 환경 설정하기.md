# Spring Bootì—ì„œ kafka í™˜ê²½ ì„¤ì •í•˜ê¸°

## 1. spring-kafkaì™€ spring-cloud-stream ì†Œê°œ

 - spring-kafkaëŠ” Kafkaë¥¼ ì§ì ‘ ì œì–´í•˜ë©°, Kafkaì˜ ê°•ë ¥í•œ ê¸°ëŠ¥ì„ í™œìš© ê°€ëŠ¥
 - spring-cloud-streamì€ ë©”ì‹œì§• ì‹œìŠ¤í…œì„ ì¶”ìƒí™”í•˜ì—¬ ìœ ì—°í•œ ê°œë°œì´ ê°€ëŠ¥
 - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì—ì„œëŠ” spring-cloud-streamì´ ìœ ë¦¬í•  ìˆ˜ ìˆìŒ
 - Kafka ê¸°ëŠ¥ì„ ì„¸ë°€í•˜ê²Œ ë‹¤ë¤„ì•¼ í•œë‹¤ë©´ spring-kafkaê°€ ë” ì í•©
 - âœ… Kafkaì— ìµœì í™”ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•œë‹¤ë©´ â†’ spring-kafka
 - âœ… Kafka ì™¸ì—ë„ RabbitMQ, Pulsar ë“±ì„ ì‚¬ìš©í•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ë©´ â†’ spring-cloud-stream
 - âœ… ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì—ì„œ ë©”ì‹œì§•ì„ ì¶”ìƒí™”í•˜ë ¤ë©´ â†’ spring-cloud-stream
 - âœ… Kafkaì˜ ê³ ê¸‰ ê¸°ëŠ¥(íŠ¸ëœì­ì…˜, ì¬ì‹œë„, Seek ë“±)ì„ ì‚¬ìš©í•˜ë ¤ë©´ â†’ spring-kafka

<div align="center">
    <img src="./images/03.PNG">
</div>
<br/>

### 1-1. Spring for Apache Kafka (spring-kafka)

__spring-kafka__ëŠ” Kafka Producer & Consumer APIë¥¼ Spring ë°©ì‹ìœ¼ë¡œ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

Kafkaë¥¼ ì§ì ‘ ì»¨íŠ¸ë¡¤í•  ìˆ˜ ìˆìœ¼ë©°, ì„¸ë°€í•œ ì„¤ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

 - Kafka Producer, Consumer APIë¥¼ Spring ë°©ì‹ìœ¼ë¡œ ì‰½ê²Œ ì‚¬ìš© ê°€ëŠ¥
 - KafkaTemplateì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì „ì†¡
 - @KafkaListenerë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì†Œë¹„
 - íŠ¸ëœì­ì…˜ ë° ì—ëŸ¬ í•¸ë“¤ë§ì„ ì„¸ë°€í•˜ê²Œ ì¡°ì • ê°€ëŠ¥
 - Kafkaì˜ ê³ ê¸‰ ê¸°ëŠ¥ ì§€ì› (ì˜ˆ: SeekToCurrentErrorHandler, ì¬ì‹œë„ ì •ì±… ë“±)

```xml
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
    <version>3.0.10</version>
</dependency>
```

 - `Producer`
```java
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Service;

@RequiredArgsConstructor
@Service
public class KafkaProducerService {
    private final KafkaTemplate<String, String> kafkaTemplate;

    public void sendMessage(String topic, String message) {
        kafkaTemplate.send(topic, message);
    }
}
```

 - `Consumer`
```java
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;

@Service
public class KafkaConsumerService {

    @KafkaListener(topics = "my-topic", groupId = "my-group")
    public void listen(ConsumerRecord<String, String> record) {
        System.out.println("Received message: " + record.value());
    }
}
```

### 1-2. Spring Cloud Stream (spring-cloud-stream)

spring-cloud-streamì€ Kafka, RabbitMQ ë“± ë©”ì‹œì§• ì‹œìŠ¤í…œì„ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

Kafkaë¿ë§Œ ì•„ë‹ˆë¼ RabbitMQ, Pulsar ë“±ë„ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë©°, ë©”ì‹œì§• ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°œë°œì„ ì‰½ê²Œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.

 - Kafka, RabbitMQ ë“± ë‹¤ì–‘í•œ ë©”ì‹œì§€ ë¸Œë¡œì»¤ë¥¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥
 - @StreamListener ë˜ëŠ” @ServiceActivatorë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì†Œë¹„
 - ì„¤ì •ë§Œ ë³€ê²½í•˜ë©´ ë‹¤ë¥¸ ë©”ì‹œì§• ì‹œìŠ¤í…œìœ¼ë¡œ êµì²´ ê°€ëŠ¥ (ex: Kafka â†’ RabbitMQ)
 - Binder ê°œë…ì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ë¸Œë¡œì»¤ì™€ ë…ë¦½ì ì¸ ì½”ë“œ ì‘ì„± ê°€ëŠ¥

```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-stream-binder-kafka</artifactId>
    <version>3.2.3</version>
</dependency>
```

 - `yml`
```yml
spring:
  cloud:
    stream:
      function:
        definition: processMessage
      bindings:
        processMessage-in-0:
          destination: my-topic
          group: my-group
```

 - `ë©”ì‹œì§€ ì²˜ë¦¬`
```java
import org.springframework.context.annotation.Bean;
import org.springframework.messaging.Message;
import org.springframework.stereotype.Service;
import java.util.function.Consumer;

@Service
public class MessageProcessor {

    @Bean
    public Consumer<Message<String>> processMessage() {
        return message -> System.out.println("Received: " + message.getPayload());
    }
}
```

## 2. Kafka Topic ìƒì„±

```bash
kafka-topics.sh --create \
  --bootstrap-server localhost:9092 \
  --replication-factor 2 \
  --partitions 3 \
  --topic my-json-topic \
  --config retention.ms=604800000
```

## 3. spring-cloud-stream ì„¤ì •

### 3-1. Spring Cloud Streamì˜ ê¸°ë³¸ êµ¬ì¡°

Spring Cloud Streamì˜ í•µì‹¬ ê°œë…ì€ ë°”ì¸ë”(Binder), ë°”ì¸ë”©(Binding), ì±„ë„(Channel) ì…ë‹ˆë‹¤.

 - __ğŸ”¹ 1. Binder (ë°”ì¸ë”)__
    - Kafka, RabbitMQ ê°™ì€ ë©”ì‹œì§€ ë¸Œë¡œì»¤ì™€ í†µì‹ í•˜ëŠ” ì¤‘ê°„ ê³„ì¸µ
    - íŠ¹ì • ë©”ì‹œì§• ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
    - spring-cloud-stream-binder-kafka, spring-cloud-stream-binder-rabbit ë“±ì˜ ë°”ì¸ë” ì‚¬ìš© ê°€ëŠ¥
 - __ğŸ”¹ 2. Binding (ë°”ì¸ë”©)__
    - ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œì™€ ë©”ì‹œì§€ ë¸Œë¡œì»¤ë¥¼ ì—°ê²°í•˜ëŠ” ì—­í• 
    - input / output ë°”ì¸ë”©ì„ í†µí•´ ë©”ì‹œì§€ë¥¼ ì£¼ê³ ë°›ìŒ
 - __ğŸ”¹ 3. Channel (ì±„ë„)__
    - ë‚´ë¶€ì ìœ¼ë¡œ Spring Integrationì„ ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ë¥¼ ì£¼ê³ ë°›ëŠ” ë…¼ë¦¬ì  ê°œë…
    - í”„ë¡œê·¸ë˜ë¨¸ëŠ” ì±„ë„ì„ ì§ì ‘ ë‹¤ë£¨ì§€ ì•Šê³  ë°”ì¸ë”©ëœ í•¨ìˆ˜ë§Œ ì‚¬ìš©í•˜ë©´ ë¨

```mermaid
graph TD;
    subgraph Application
        A[Producer Supplier] --> B[Binder]
        D[Consumer Function] --> B
    end

    B -->|ë©”ì‹œì§€ ì „ì†¡| C[Kafka Topic]
    C -->|ë©”ì‹œì§€ ì†Œë¹„| B
```

<div align="center">
    <img src="./images/04.PNG">
</div>
<br/>

 - spring.cloud.stream.kafka.binder: binder ê³µí†µ ì„¤ì •
 - spring.cloud.stream.kafka.bindings: output&input ì±„ë„ì— ëŒ€í•œ ì¹´í”„ì¹´ íŠ¹í™” ì„¤ì •
 - spring.cloud.stream.bindings: output&input ì±„ë„ì— ëŒ€í•œ ê³µí†µ ì„¤ì •
 - spring.cloud.function.definition: bean ì •ì˜
 - spring.cloud.stream.function.bindings: beanê³¼ ì±„ë„ì„ ë°”ì¸ë”© í•´ì£¼ëŠ” ì—­í•  (ì±„ë„ì€ bindingsì— ì •ì˜)
```yml
spring:
  cloud:
    function: # bean ì •ì˜
      definition: myProducer;myConsumer;
    stream:
      function:
        bidings: # beanê³¼ ì±„ë„ì„ ë°”ì¸ë”© í•´ì£¼ëŠ” ì—­í•  (ì±„ë„ì€ bindingsì— ì •ì˜)
          myProducer-out-0: producer-test
          myConsumer-in-0: consumer-test
      kafka:
        binder: # binder ê³µí†µ ì„¤ì •
          brokers: localhost:9092,localhost:9093,localhost:9094
          auto-create-topics: false
          required-acks: 0
          configuration:
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
        bindings: # output&input ì±„ë„ì— ëŒ€í•œ ì¹´í”„ì¹´ íŠ¹í™” ì„¤ì •
          consumer-test:
            consumer:
              start-offset: latest
      bindings: # output&input ì±„ë„ì— ëŒ€í•œ ê³µí†µ ì„¤ì •
        consumer-test:
          group: test-consumer-group
          destination: my-json-topic
          consumer:
            concurrency: 1
        producer-test:
          destination: my-json-topic
          contentType: application/json
```

### 3-2. Spring Cloud Stream ì‚¬ìš© ì˜ˆì œ

 - `build.gradle`
```groovy
dependencies {
    // ..

    implementation 'org.springframework.cloud:spring-cloud-stream:4.0.3'
    implementation 'org.springframework.cloud:spring-cloud-stream-binder-kafka:4.0.3'
}
```

 - `application.yml`
```yml
spring:
  cloud:
    function:
      deifinition: myProducer;myConsumer;
    stream:
      function:
        bindings:
          myProducer-out-0: producer-test
          myConsumer-in-0: consumer-test
      kafka:
        binder:
          brokers: localhost:9092,localhost:9093,localhost:9094
          auto-create-topics: false
          required-acks: 0
          configuration:
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
        bindings:
          consumer-test:
            consumer:
              start-offset: latest
      bindings:
        producer-test:
          destination: my-json-topic
          content-type: application/json
        consumer-test:
          destination: my-json-topic
          group: test-consumer-group
          consumer:
            concurrency: 1
```

 - `MyConsumer & MyProducer`
```java
@Data
public class MyMessage {
    private int id;
    private int age;
    private String name;
    private String content;
}

// Consumer
import org.springframework.messaging.Message;
import org.springframework.stereotype.Component;
import java.util.function.Consumer;

@Component
public class MyConsumer implements Consumer<Message<MyMessage>> {
    @Override
    public void accept(Message<MyMessage> message) {
        System.out.println("Message arrived! - " + message.getPayload());
    }
}

// Producer
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.Message;
import org.springframework.messaging.support.MessageBuilder;
import org.springframework.stereotype.Component;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Sinks;
import java.util.function.Supplier;

@Component
public class MyProducer implements Supplier<Flux<Message<MyMessage>>> {

    private final Sinks.Many<Message<MyMessage>> sinks = Sinks.many().unicast().onBackpressureBuffer();

    public void sendMessage(MyMessage myMessage) {
        Message<MyMessage> message = MessageBuilder
                .withPayload(myMessage)
                .setHeader(KafkaHeaders.KEY, String.valueOf(myMessage.getAge()))
                .build();
        sinks.emitNext(message, Sinks.EmitFailureHandler.FAIL_FAST);
    }

    @Override
    public Flux<Message<MyMessage>> get() {
        return sinks.asFlux();
    }
}
```

 - `MyController`
    - "/message" ì—”ë“œí¬ì¸íŠ¸ ìš”ì²­ì‹œ í”„ë¡œë“€ì„œë¡œ ë©”ì‹œì§€ ë°œí–‰
```java
@RequiredArgsConstructor
@RestController
public class MyController {

    private final MyProducer myProducer;

    @RequestMapping("/hello")
    String hello() {
        return "Hello World";
    }

    @PostMapping("/message")
    void message(
        @RequestBody MyMessage message
    ) {
        myProducer.sendMessage(message);
    }
}
```

## 4. Spring Kafka ì„¤ì •

 - `build.gradle`
```groovy
dependencies {
    // ..

    implementation 'org.springframework.kafka:spring-kafka:3.1.0'
}
```

 - `application.yml`
    - acks 0ì€ í”„ë¡œë“€ì„œê°€ ë¸Œë¡œì»¤ì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚¸ í›„ ê²°ê³¼ì— ëŒ€í•´ì„œ ì‹ ê²½ì“°ì§€ ì•ŠëŠ”ë‹¤.
    - acks 1ì€ ë¦¬ë” íŒŒí‹°ì…˜ì—ì„œ ë©”ì‹œì§€ë¥¼ ë°›ì•˜ë‹¤ëŠ” ì‘ë‹µì´ ì˜¤ë©´ í”„ë¡œë“€ì„œê°€ ë©”ì‹œì§€ ë°œí–‰ ì„±ê³µ ì²˜ë¦¬í•œë‹¤. ë§Œì•½, ë¦¬ë” íŒŒí‹°ì…˜ì— ë©”ì‹œì§€ê°€ ì „ì†¡ë˜ì§€ ì•Šì•˜ë‹¤ê³  íŒë‹¨í•˜ë©´ ì¬ì‹œë„í•˜ê²Œ ëœë‹¤.
    - acks -1ì€ ë¦¬ë” íŒŒí‹°ì…˜ê³¼ íŒ”ë¡œì›Œ íŒŒí‹°ì…˜ì— ëª¨ë‘ ë³µì œê°€ ì„±ê³µí•´ì•¼ ì •ìƒì´ë¼ê³  íŒë‹¨í•œë‹¤. ê·¸ê²Œ í™•ì¸ë˜ì§€ ì•Šìœ¼ë©´ ì¬ì‹œë„ í•˜ê²Œ ëœë‹¤.
```yml
spring:
  kafka:
    bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      auto-offset-reset: latest
      properties:
        spring.json.trusted.packages: "*"
        allow.auto.create.topics: false
    listener:
      concurrency: 1
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      acks: 1
```

 - `MyConsumer & MyProducer`
    - Producer
        - KafkaTemplateì„ ì‚¬ìš©í•˜ì—¬ Kafkaë¡œ ë©”ì‹œì§€ë¥¼ ì „ì†¡
        - send(topic, message)ë¡œ ë©”ì‹œì§€ë¥¼ ë³´ëƒ„
        - ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì¬ì‹œë„ ê°€ëŠ¥
    - Consumer
        - @KafkaListener: í† í”½ì„ êµ¬ë…í•˜ê³  ë©”ì‹œì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì‹¤í–‰
        - ConsumerRecord: ë©”ì‹œì§€ í‚¤ì™€ ê°’ì„ í¬í•¨í•˜ëŠ” Kafka ë°ì´í„° êµ¬ì¡°
```java
// MyConsumer: ë©”ì‹œì§€ ì†Œë¹„
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
public class MyConsumer {

    @KafkaListener(
        topics = { "my-json-topic" },
        groupId = "test-consumer-group"
    )
    public void accept(ConsumerRecord<String, MyMessage> message) {
        System.out.println("Message arrived! - " + message.value());
    }
}

// MyProducer: ë©”ì‹œì§€ ë°œí–‰
import lombok.RequiredArgsConstructor;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.stereotype.Component;

@RequiredArgsConstructor
@Component
public class MyProducer {

    private final KafkaTemplate<String, MyMessage> kafkaTemplate;

    public void sendMessage(MyMessage myMessage) {
        kafkaTemplate.send("my-json-topic", String.valueOf(myMessage.getAge()), myMessage);
    }
}
```

## 5. Spring Kafka ì„¤ì • (Produce, Consume)

### 5-1. KafkaAutoConfiguration

KafkaAutoConfigurationì€ Spring Bootì—ì„œ Kafka ì„¤ì •ì„ ìë™ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

Spring Boot ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ Kafka ê´€ë ¨ ë¹ˆ(Bean)ì„ ìë™ìœ¼ë¡œ ë“±ë¡í•´ ì£¼ë¯€ë¡œ, ë³„ë„ì˜ ë³µì¡í•œ ì„¤ì • ì—†ì´ Kafkaë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

 - KafkaAutoConfigurationì€ application.ymlì—ì„œ ì •ì˜í•œ Kafka ì„¤ì •ì„ ìë™ìœ¼ë¡œ ì ìš©í•˜ë©°, í•´ë‹¹ ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ KafkaTemplate, ProducerFactory, ConsumerFactory ë“±ì´ ìë™ìœ¼ë¡œ ì„¤ì •ëœë‹¤.
 - KafkaTemplate: Kafka ë©”ì‹œì§€ë¥¼ ë³´ë‚´ëŠ” í•µì‹¬ í´ë˜ìŠ¤
 - DefaultKafkaProducerFactory: Kafka í”„ë¡œë“€ì„œë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬
 - KafkaListenerContainerFactory: Kafka ë¦¬ìŠ¤ë„ˆë¥¼ ê´€ë¦¬í•˜ëŠ” ì»¨í…Œì´ë„ˆ
 - ConcurrentKafkaListenerContainerFactory: @KafkaListenerë¥¼ ì‚¬ìš©í•  ë•Œ í•„ìš”í•œ ì„¤ì •ì„ ë‹´ë‹¹
 - DefaultKafkaConsumerFactory: Kafka ì»¨ìŠˆë¨¸ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬
```java
// @ConditionalOnClass(KafkaTemplate.class) â†’ Kafka ê´€ë ¨ í´ë˜ìŠ¤ê°€ í´ë˜ìŠ¤íŒ¨ìŠ¤ì— ìˆì„ ê²½ìš°ë§Œ í™œì„±í™”
// @ConditionalOnProperty(prefix = "spring.kafka", name = "enabled", matchIfMissing = true) â†’ spring.kafka.enabled=trueì¼ ê²½ìš° í™œì„±í™” (ê¸°ë³¸ê°’: í™œì„±í™”ë¨)
// @EnableConfigurationProperties(KafkaProperties.class) â†’ application.ymlì˜ spring.kafka ê°’ì„ KafkaProperties ê°ì²´ì— ë°”ì¸ë”©
// @Import(...) â†’ Kafka ê´€ë ¨ ì„¤ì • í´ë˜ìŠ¤ë¥¼ í•¨ê»˜ ë“±ë¡
@Configuration(proxyBeanMethods = false)
@ConditionalOnClass(KafkaTemplate.class)
@ConditionalOnProperty(prefix = "spring.kafka", name = "enabled", matchIfMissing = true)
@EnableConfigurationProperties(KafkaProperties.class)
@Import({KafkaTemplateConfiguration.class, KafkaAnnotationDrivenConfiguration.class})
public class KafkaAutoConfiguration {
}
```

### 5-2. KafkaAutoConfigurationì„ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§ì ‘ ì„¤ì •

 - `application.yml`
    - Kafka ì„¤ì •ì„ 2ê°œ ì ìš©í•˜ê¸° ìœ„í•´ spring.kafka í•˜ìœ„ì— jsonê³¼ string ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ì„¤ì •ì„ ì •ì˜
```yml
spring:
  kafka:
    json:
      bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
      consumer:
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
        auto-offset-reset: latest
      listener:
        concurrency: 1
      producer:
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
        acks: 1
    string:
      bootstrap-servers: localhost:9092,localhost:9093,localhost:9094
      consumer:
        key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
        value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      listener:
        concurrency: 1
      producer:
        key-serializer: org.apache.kafka.common.serialization.StringSerializer
        value-serializer: org.apache.kafka.common.serialization.StringSerializer
        acks: 0
```

 - `KafkaConfig`
```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.springframework.boot.autoconfigure.kafka.KafkaProperties;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class KafkaConfig {

    @Bean
    @Primary
    @ConfigurationProperties("spring.kafka.json")
    public KafkaProperties kafkaProperties() {
        return new KafkaProperties();
    }

    @Bean
    @Primary
    public ConsumerFactory<String, Object> consumerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, kafkaProperties.getConsumer().getKeyDeserializer());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, kafkaProperties.getConsumer().getValueDeserializer());
        props.put(JsonDeserializer.TRUSTED_PACKAGES, "*");
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");
        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, "false");
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.setConcurrency(1);

        return factory;
    }

    @Bean
    @Primary
    public ProducerFactory<String, Object> producerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, kafkaProperties.getProducer().getKeySerializer());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, kafkaProperties.getProducer().getValueSerializer());
        props.put(ProducerConfig.ACKS_CONFIG, kafkaProperties.getProducer().getAcks());
        return new DefaultKafkaProducerFactory<>(props);
    }

    // KafkaTemplateì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° KafkaAutoConfigurationì˜ ìë™ ì„¤ì •ì´ ì œì™¸ëœë‹¤.
    // ì»´í¬ë„ŒíŠ¸ ìŠ¤ìº”ì‹œ KafkaAutoConfigurationì„ exclude í•˜ë„ë¡ ì •ì˜í•  ìˆ˜ë„ ìˆë‹¤.
    @Bean
    @Primary
    public KafkaTemplate<String, ?> kafkaTemplate(KafkaProperties kafkaProperties) {
        return new KafkaTemplate<>(producerFactory(kafkaProperties));
    }
}
```

 - `SecondKafkaConfig`
```java
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.boot.autoconfigure.kafka.KafkaProperties;
import org.springframework.boot.context.properties.ConfigurationProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.annotation.EnableKafka;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.*;

import java.util.HashMap;
import java.util.Map;

@Configuration
@EnableKafka
public class SecondKafkaConfig {

    @Bean
    @Qualifier("secondKafkaProperties")
    @ConfigurationProperties("spring.kafka.string")
    public KafkaProperties secondKafkaProperties() {
        return new KafkaProperties();
    }

    @Bean
    @Qualifier("secondConsumerFactory")
    public ConsumerFactory<String, Object> secondConsumerFactory(KafkaProperties secondKafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, secondKafkaProperties.getBootstrapServers());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, secondKafkaProperties.getConsumer().getKeyDeserializer());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, secondKafkaProperties.getConsumer().getValueDeserializer());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "latest");
        props.put(ConsumerConfig.ALLOW_AUTO_CREATE_TOPICS_CONFIG, "false");
        return new DefaultKafkaConsumerFactory<>(props);
    }

    @Bean
    @Qualifier("secondKafkaListenerContainerFactory")
    public ConcurrentKafkaListenerContainerFactory<String, Object> secondKafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.setConcurrency(1);

        return factory;
    }

    @Bean
    @Qualifier("secondKafkaListenerContainerFactory")
    public ProducerFactory<String, Object> secondProducerFactory(KafkaProperties kafkaProperties) {
        Map<String, Object> props = new HashMap<>();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapServers());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, kafkaProperties.getProducer().getKeySerializer());
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, kafkaProperties.getProducer().getValueSerializer());
        props.put(ProducerConfig.ACKS_CONFIG, kafkaProperties.getProducer().getAcks());
        return new DefaultKafkaProducerFactory<>(props);
    }

    @Bean
    @Qualifier("secondKafkaTemplate")
    public KafkaTemplate<String, ?> secondKafkaTemplate(KafkaProperties kafkaProperties) {
        return new KafkaTemplate<>(secondProducerFactory(kafkaProperties));
    }
}
```

 - `Producer & Consumer(Second)`
```java
// Producer
@RequiredArgsConstructor
@Component
public class MySecondProducer {

    @Qualifier("secondKafkaTemplate")
    private final KafkaTemplate<String, String> secondKafkaTemplate;

    public void sendMessageWithKey(String key, String message) {
        secondKafkaTemplate.send(MY_SECOND_TOPIC, key, message);
    }
}

// Consumer
@Component
public class MySecondConsumer {

    @KafkaListener(
        topics = { MY_SECOND_TOPIC },
        groupId = "test-consumer-group",
        containerFactory = "secondKafkaListenerContainerFactory"
    )
    public void accept(ConsumerRecord<String, String> message) {
        System.out.println("[Second Consumer] Message arrived! - " + message.value());
        System.out.println("[Second Consumer] Offset - " + message.offset() + " / Partition - " + message.partition());
    }
}
```
