# 예외 통제(Consumer 심화)

## 1. 발생할 수 있는 이슈

프로듀서는 메시지를 발행하는 책임이 끝이지만, 컨슈머는 메시지를 소비하면서 실질적인 데이터 처리가 필요하다. 때문에, 카프카를 사용하면서 대부분 상황 장애는 컨슈머 측에서 많이 발생할 수 있다.

### 1-1. 컨슈머 관점에서의 예외 바라보기

 - JsonProcessingTimeoutException -> Not Retryable (재시도 불가)
 - TimeoutException -> Retryable (재시도 가능)

## 2. 대비 방안 - Retry

 - `KafkaConfig`
```java
@Configuration
@EnableKafka
public class KafkaConfig {

    // ..

    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);

        // 1. 기본 예외 핸들러 등록
        //DefaultErrorHandler errorHandler = new DefaultErrorHandler();
        //factory.setCommonErrorHandler(errorHandler);

        // 2. 고정 간격 예외 핸들러 등록 (1초간격으로 2회 재시도)
        //DefaultErrorHandler errorHandler = new DefaultErrorHandler(new FixedBackOff(1000L, 2L));
        //factory.setCommonErrorHandler(errorHandler);

        // 3. 예외 핸들러 등록 (Not Retryable)
        DefaultErrorHandler errorHandler = new DefaultErrorHandler(generateBackOff());
        errorHandler.addNotRetryableExceptions(IllegalArgumentException.class);
        factory.setCommonErrorHandler(errorHandler);

        return factory;
    }

    private BackOff generateBackOff() {
        // 1000ms 간격으로 2의 지수 간격으로 시도 (1, 2, 4, 8)
        ExponentialBackOff backOff = new ExponentialBackOff(1000, 2);
        //backOff.setMaxAttempts(1); // 최대 재시도 횟수
        backOff.setMaxElapsedTime(10000); // 10,000ms까지만 재시도
        return backOff;
    }
}
```

## 3. 대비 방안 - ErrorHandler

에러 핸들러 정책도 커스터마이징이 가능하다.

기본적으로 컨슈머 실행 도중 실패가 일어나면 재시도가 발생하고, 재시도에 실패하면 다음 메시지부터 처리하게 된다. 

이것을 커스터 마이징하여 실패 구간에서 정지하게 할 수도 있다. 하지만, 뒤에 메시지를 처리하지 못하여 랙이 쌓이게 된다. 메시지를 하나하나 제대로 컨슈밍하는게 중요하다면 정지하는게 좋을 수도 있다.

 - `KafkaConfig`
    - CommonContainerStoppingErrorHandler를 등록하면 실패한 구간에서 정지하게 된다.
```java
@Configuration
@EnableKafka
public class KafkaConfig {

    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
        ConsumerFactory<String, Object> consumerFactory
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);

        // 예외 핸들러 등록 (ContainerStopping 에러 핸들러)
        DefaultErrorHandler errorHandler = new CommonContainerStoppingErrorHandler();
        factory.setCommonErrorHandler(errorHandler);

        return factory;
    }
}
```

 - `KafkaConfig`
    - 에러 핸들러를 별도의 빈으로 등록
```java
@Configuration
@EnableKafka
public class KafkaConfig {

    @Bean
    @Primary
    CommonErrorHandler errorHandler() {
        CommonContainerStoppingErrorHandler cseh = new CommonContainerStoppingErrorHandler();
        AtomicReference<Consumer<? ,?>> consumer2 = new AtomicReference<>();
        AtomicReference<MessageListenerContainer> container2 = new AtomicReference<>();

        DefaultErrorHandler errorHandler = new DefaultErrorHandler((rec, ex) -> {
            // container stopping error handler를 통해서 해당 컨테이너(컨슈머)를 중지시킨다.
            // 반환은 DefaultErrorHandler를 사용하고, 그 안에서 container stopping error handler를 통해서 컨테이너를 중지
            cseh.handleRemaining(ex, Collections.singletonList(rec), consumer2.get(), container2.get());
        }, generateBackOff()) {

            @Override
            public void handleRemaining(
                    Exception thrownException,
                    List<ConsumerRecord<?, ?>> records,
                    Consumer<?, ?> consumer,
                    MessageListenerContainer container
            ) {
                consumer2.set(consumer);
                container2.set(container);
                super.handleRemaining(thrownException, records, consumer, container);
            }
        };
        errorHandler.addNotRetryableExceptions(IllegalArgumentException.class);
        return errorHandler;
    }

    private BackOff generateBackOff() {
        ExponentialBackOff backOff = new ExponentialBackOff(1000, 2);
        backOff.setMaxElapsedTime(10000);
        return backOff;
    }

    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
            ConsumerFactory<String, Object> consumerFactory,
            CommonErrorHandler errorHandler
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);
        factory.setCommonErrorHandler(errorHandler);
        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        return factory;
    }
}
```

## 4. 대비 방안 - DLT(Dead Letter Topic)

Kafka에서 DLT(Dead Letter Topic)는 정상적으로 처리되지 않은 메시지를 별도의 토픽에 저장하여 후속 처리할 수 있도록 하는 기능입니다. 일반적으로 Kafka는 메시지를 생산(produce)하고 소비(consume)하는 구조인데, 소비자가 특정 메시지를 지속적으로 처리하지 못할 경우 해당 메시지를 Dead Letter Topic으로 보내서 나중에 재처리하거나 분석할 수 있도록 합니다.

 - 컨슈머에서 실패한 경우 재시도를 실행하고, 재시도마저 실패한 경우 DLT 라는 새로운 토픽에 실패한 메시지를 발행하고, 이후 메시지를 처리한다.


```java
@Configuration
@EnableKafka
public class KafkaConfig {


    @Bean
    @Primary
    public ConcurrentKafkaListenerContainerFactory<String, Object> kafkaListenerContainerFactory(
            ConsumerFactory<String, Object> consumerFactory,
            KafkaTemplate<String, Object> kafkaTemplate
    ) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory);

        // DLT PublishingRecoverer 등록
        // 데드 레터를 처리하는 컨슈머 역할을 한다. 안에서 데드 레터 토픽을 발행해주어야 한다.
        // 기본적으로 동일한 토픽명에 ".DLT"가 붙은 토픽이 발행된다.
        factory.setCommonErrorHandler(
            new DefaultErrorHandler(
                new DeadLetterPublishingRecoverer(kafkaTemplate), generateBackOff()
            )
        );

        // 커스텀한 DeadLetterPublishingRecoverer 등록
        // 원하는 이름으로 DLT 생성
        factory.setCommonErrorHandler(
            new DefaultErrorHandler(
                (record, exception) -> {
                    kafkaTemplate.send(MY_CUSTOM_CDC_TOPIC_DLT, (String) record.key(), record.value());
                    System.out.println("Give up! - " + exception.getMessage());
                }, 
                generateBackOff()
            )
        );

        factory.getContainerProperties().setAckMode(ContainerProperties.AckMode.MANUAL);
        return factory;
    }
}
```
